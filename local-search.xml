<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Docker 容器终止运行方式小记</title>
    <link href="undefined2020/08/21/docker-termination-description/"/>
    <url>2020/08/21/docker-termination-description/</url>
    
    <content type="html"><![CDATA[<p>简要介绍 <code>docker stop/kill</code> ，以及如何更优雅地触发容器退出流程</p><a id="more"></a><h2 id="docker-容器根进程与容器退出机制"><a href="#docker-容器根进程与容器退出机制" class="headerlink" title="docker 容器根进程与容器退出机制"></a>docker 容器根进程与容器退出机制</h2><p>docker 作为一种轻量级的“虚拟化”技术，通过 Linux 提供的 cgroup 和 namespace 等机制限制容器内进程的资源占用及其对宿主机资源的可见性。当容器启动时，宿主机 Linux 内核会为此容器创建一个 PID namespace 。容器的启动进程在宿主机上看来是一个普通的进程，而在该容器的 PID namespace 中看上去 <code>PID</code> = 1 ，即它是此容器内的根进程。当容器内 PID=1 的进程停止运行时，容器便停止运行了。</p><p>作为例子，我们启动一个 alpine linux 的容器，使其执行 <code>ping localhost</code> 命令：</p><pre><code class="shell">## --rm 表示容器结束时自动删除，免去手动清理无用容器的工作docker run --rm --entrypoint ping alpine localhost</code></pre><p>运行 <code>docker ps</code> 找到这个 alpine 容器，我们可以使用 <code>docker inspect</code> 命令查看到此容器的根进程在宿主机上的进程号：</p><pre><code class="shell"># docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES52100c256521        alpine              &quot;ping localhost&quot;    9 seconds ago       Up 8 seconds                                 zen_mccarthy# docker inspect 52100 -f &#39;{{.State.Pid}}&#39;9509</code></pre><blockquote><p><code>docker inspect &lt;container_id&gt;</code> 会以 json 格式打印容器的信息。<code>-f</code>参数后面接的格式化串声明 <code>docker inspect</code> 只将容器根进程的进程号打印出来。</p></blockquote><p>然后在宿主机执行<code>ps &lt;Pid&gt;</code>，果然是能看到一个 <code>ping localhost</code> 进程的：</p><pre><code class="shell"># ps 9509  PID TTY      STAT   TIME COMMAND 9509 ?        Ss     0:00 ping localhost</code></pre><p>使用 <code>kill</code> 命令向其发送一个 <code>SIGINT</code> 信号令其终止运行（<code>SIGINT</code>信号代表键盘发送的终止信号 ctrl-C ， <code>ping</code> 命令接收到此信号后会正常退出并打印统计信息） <code>kill -s SIGINT 9509</code> ，最终在运行容器的控制台，我们看到的输出类似下面这样</p><pre><code class="shell"># docker run --rm --entrypoint ping alpine localhostPING localhost (127.0.0.1): 56 data bytes64 bytes from 127.0.0.1: seq=0 ttl=64 time=0.032 ms…… 忽略中间日志 ……64 bytes from 127.0.0.1: seq=26 ttl=64 time=0.046 ms--- localhost ping statistics ---27 packets transmitted, 27 packets received, 0% packet lossround-trip min/avg/max = 0.032/0.046/0.065 ms</code></pre><p>说明容器中的 <code>ping</code> 进程确实是接收到 <code>SIGINT</code> 信号正常终止了。并且此时再次运行 <code>docker ps</code> 是看不到这个容器的，说明<strong>容器根进程结束运行的话，容器也会终止运行</strong>。</p><blockquote><p>以上现象也能解释为什么容器的启动命令不能用 <code>nohup</code> 等形式将应用服务进程作为后台运行 —— 如果应用服务的进程不是作为主进程运行在前台，那么容器就会因为根进程执行完成而结束运行。</p></blockquote><h2 id="docker-stop-和-docker-kill"><a href="#docker-stop-和-docker-kill" class="headerlink" title="docker stop 和 docker kill"></a>docker stop 和 docker kill</h2><p><code>docker stop</code> 命令和 <code>docker kill</code> 命令都可以用于终止正在运行的 docker 容器。差别在于， <code>docker stop</code> 默认会先发送一个 <code>SIGTERM</code> 信号给容器内的根进程，如果一段时间内容器没有结束运行（默认10秒），则再向容器发送一个 <code>SIGKILL</code> 将容器根进程强制结束。而 <code>docker kill</code> 是默认直接给容器内的根进程发送一个 <code>SIGKILL</code> 信号，类似于 <code>kill -9</code> 强杀进程。</p><p>两者的设计目的并不相同， <code>docker stop</code> 主要是为了优雅停止容器的运行。它的选项 <code>--time , -t</code> 表示在强制杀进程之前等待多少秒。<br>而 <code>docker kill</code> 跟 Linux 的 <code>kill</code> 命令一样，可以用来给容器内的根进程发送进程信号。具体的信号内容通过参数 <code>--signal , -s</code> 来指定，参数值可以是<em>信号名</em>或者是它的<em>数字编号</em>。</p><p>需要注意的是，<strong>容器只把进程信号发送给它的根进程</strong>。这也比较容易理解，Linux宿主机上也是由 PID=1 的根进程负责处理宿主机上的进程结束工作。容器的 PID namespace 与此类似， docker 也只会把外来的进程信号传递给 PID=1 的进程，这个进程再来决定信号该如何处理。</p><blockquote><p>PID1进程对于操作系统而言具有特殊意义。操作系统的PID1进程是init进程，以守护进程方式运行，是所有其他进程的祖先，具有完整的进程生命周期管理能力。在Docker容器中，PID1进程是启动进程，它也会负责容器内部进程管理的工作。而这也将导致进程管理在Docker容器内部和完整操作系统上的不同。<br>—— <a href="https://www.cnblogs.com/ilinuxer/p/6188303.html" target="_blank" rel="noopener" title="理解Docker容器的进程管理">理解Docker容器的进程管理</a></p></blockquote><h2 id="正确编写启动脚本确保容器优雅退出"><a href="#正确编写启动脚本确保容器优雅退出" class="headerlink" title="正确编写启动脚本确保容器优雅退出"></a>正确编写启动脚本确保容器优雅退出</h2><p>让我们首先来看这样一个启动脚本：</p><pre><code class="shell">#!/bin/shping localhost</code></pre><p>Dockerfile 如下：</p><pre><code class="shell">FROM openjdk:8-alpineWORKDIR /homeCOPY start.sh .ENTRYPOINT [&quot;sh&quot;, &quot;./start.sh&quot;]</code></pre><p>打包为 test 镜像，执行 <code>docker run --rm test</code> 启动 test 镜像。此时如果使用 <code>docker kill -s SIGINT &lt;container_id&gt;</code> 以向容器内发送 <code>ctrl+C</code> ，能否触发 <code>ping</code> 进程打印统计信息并终止运行呢？</p><p>实际实验的结果是，不行。<br>查看容器内的进程情况，我们可以看到 PID=1 的进程是 <code>sh ./start.sh</code>，而 <code>ping localhost</code> 进程是它的子进程：</p><pre><code class="shell"># docker exec ed882 ps -o pid,ppid,user,argsPID   PPID  USER     COMMAND    1     0 root     sh ./start.sh    8     1 root     ping localhost    9     0 root     ps -o pid,ppid,user,args</code></pre><p>很明显， <code>ping localhost</code> 进程不是容器的根进程，我们发送的 <code>SIGINT</code> 信号只会被 <code>sh ./start.sh</code> 进程接收，但它又不会将信号转发给 <code>ping localhost</code> 进程，于是 <code>SIGINT</code> 信号就这么被忽略了，好像什么都没发生过。</p><p>解决这个问题的方式通常是确保容器内的业务进程是容器的根进程（docker部署方式推荐一个容器一个业务进程，所以尽量避免将多个业务部署在同一个容器中），为此，需要修改启动脚本：</p><pre><code class="shell">#!/bin/shexec ping localhost # 注意这一行的变化</code></pre><p><code>exec</code> 命令用于运行指定的命令，并以此命令的运行进程替换掉当前进程，继承当前进程的 PID。直观地说，运行上面的启动脚本时，当执行到 <code>exec ping localhost</code> ， <code>ping localhost</code> 进程将会取代 <code>sh ./start.sh</code> 进程在进程树中的位置，并沿用 <code>sh ./start.sh</code> 进程的 PID，也就是变成容器内的根进程了。</p><p>重新打个 test 镜像包试一下：</p><pre><code class="shell"># docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES71cde237ce32        test                &quot;sh ./start.sh&quot;     10 seconds ago      Up 9 seconds                                 confident_mcclintock# docker exec 71cde cat /home/start.sh#!/bin/shexec ping localhost# docker exec 71cde ps -o pid,ppid,user,argsPID   PPID  USER     COMMAND    1     0 root     ping localhost   15     0 root     ps -o pid,ppid,user,args</code></pre><p>现在 <code>ping localhost</code> 是容器的根进程了。运行一下 <code>docker kill -s 2 71cde</code>，容器立即结束运行，并且打出了数据包统计信息，说明它确实是接收到 <code>SIGINT</code> 信号退出的。控制台输出如下：</p><pre><code class="shell"># docker run --rm testPING localhost (127.0.0.1): 56 data bytes64 bytes from 127.0.0.1: seq=0 ttl=64 time=0.029 ms64 bytes from 127.0.0.1: seq=1 ttl=64 time=0.044 ms64 bytes from 127.0.0.1: seq=2 ttl=64 time=0.047 ms…… 忽略中间输出 ……64 bytes from 127.0.0.1: seq=85 ttl=64 time=0.046 ms--- localhost ping statistics ---86 packets transmitted, 86 packets received, 0% packet lossround-trip min/avg/max = 0.029/0.047/0.061 ms</code></pre><blockquote><p>上文演示的是 <code>docker kill</code> 发送信号，但 <code>docker stop</code> 优雅退出容器的逻辑也是一样的。</p></blockquote><p>这一点在实际的业务系统运行中也是有重要意义的。通常业务进程在结束运行前有些收尾的事情要做，比如需要确保写文件都结束，网络服务器还要保证自己处理中的业务请求都处理完成，在此过程中还不能接收新的请求。这些都要求容器内的业务进程能感知到容器将要退出运行才行。<br>所以我们在打包镜像的时候需要注意，<strong>要么在 Dockerfile 中直接启动业务进程，如果要以启动脚本拉起业务进程，需要在脚本内以 <code>exec</code> 命令启动业务。</strong></p><p>举个实际的例子， Java-Chassis 框架基于 JVM shutdown hook 实现了微服务进程的<a href="https://docs.servicecomb.io/java-chassis/zh_CN/general-development/shutdown/" target="_blank" rel="noopener" title="Java-Chassis 优雅停机">优雅停机</a>功能。该功能使得 Java-Chassis 可以在微服务进程退出时执行等待处理中的业务请求执行完成、返回 503 状态码拒绝新请求、注销微服务实例等一系列操作，这些操作可以尽量确保业务请求不受损，使 consumer 端能尽快感知到 provider 微服务实例的下线操作。用户也可以通过 <code>BootListener</code> 接口监听 <code>BEFORE_CLOSE</code> 事件来完成自定义的一些清理操作。</p><p><strong>而要确保 Java-Chassis 的优雅停机功能在容器化部署场景下正常工作，就需要用户基于上述内容调整业务进程启动方式，使得业务进程是容器内的根进程。</strong></p><p>当然 Java-Chassis 的优雅停机操作仍然只是尽力保护业务请求不受损（配合 Java-Chassis 的<a href="https://docs.servicecomb.io/java-chassis/zh_CN/references-handlers/loadbalance/#_5" target="_blank" rel="noopener" title="Java-Chassis 实例隔离">实例隔离</a>和<a href="https://docs.servicecomb.io/java-chassis/zh_CN/references-handlers/loadbalance/#_7" target="_blank" rel="noopener" title="Java-Chassis 重试策略">重试策略</a>）。 Java-Chassis 默认的重试策略是 <code>tryOnSame=0,tryOnNext=1</code> ，因此只能保证 provider 端实例一个接一个下线时业务调用不受损，而且要求实例下线的时间间隔要大于 consumer 端的 instance pull 时间间隔。否则 consumer 端本地缓存的 provider 实例列表中实际已下线的实例数大于1，就有可能造成请求路由给一个已下线的实例，又重试到另一个已下线的实例的情况，最终导致业务请求失败。</p><p>要从理论上保证实例缩容、滚动升级等涉及 provider 端实例下线的场景中微服务业务调用不受损，最好是在部署系统下线微服务实例之前将对应的实例记录状态置为不可用，让 consumer 端微服务从服务中心感知到实例状态变化后再真正下线对应的实例。但 ServiceComb 本身并没有对用户的部署方式做假设，让部署系统和服务中心联动起来也并不是一件简单的事情。 为了能以尽可能低的成本达到类似的效果， Java-Chassis 框架在新版本引入了退出前将本实例置为 <code>DOWN</code> 状态并阻塞等待的机制。<br>此机制默认不开启，配置 <code>servicecomb.boot.turnDown.waitInSeconds</code> 设置阻塞等待时间大于零即可启用。当 JVM 触发 shutdown hook 运行时，该功能会向服务中心发请求将本实例的状态置为 <code>DOWN</code>，并根据用户配置的阻塞时长进行等待。在此期间， shutdown hook 的运行线程是被阻塞住的，因此 JVM 还不会退出，微服务业务还能继续处理请求。阻塞完成后 JVM shutdown hook 逻辑放通继续执行，微服务真正退出。在阻塞的这一段时间里， consumer 端微服务就能够从服务中心查询到即将下线的 provider 实例状态变为不可用了，于是业务流量便提前绕过此实例，从根源上避免了业务调用失败。<br>使用此功能还需要部署系统给予业务服务足够的退出时间，这可能需要用户根据 consumer 端的 instance pull 时间间隔进行设置，以确保 docker / K8s 等部署运行系统不会提前强制结束进程。</p><blockquote><p>该功能的代码在 <code>SCBEngine#blockShutDownOperationForConsumerRefresh</code> 方法中。</p></blockquote><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>在 docker 文档 <a href="https://docs.docker.com/engine/reference/commandline/kill/" target="_blank" rel="noopener" title="docker kill | Docker Documentation">docker kill</a> 中有说明如果 <code>ENTRYPOINT</code> 和 <code>CMD</code> 是以 shell 风格书写的，会导致启动命令以 <code>/bin/sh -c</code> 方式运行，是 <code>sh</code> 进程的子进程，无法获得信号。但笔者在实测时发现即使以 shell 风格书写 Dockerfile 中的启动命令， <code>docker history</code> 查看镜像分层看到的也确实是 <code>ENTRYPOINT [&quot;/bin/sh&quot; &quot;-c&quot; &quot;sh ./start.sh&quot;]</code> ，启动容器后仍然能看到启动脚本中拉起的业务进程的 PID=1 （前提条件是启动脚本以 <code>exec</code> 命令运行业务）。推测是内核或者 docker 版本不同导致与文档所描述的行为不同。<br>即使如此，书写 Dockerfile 时仍然建议遵循 exec 风格。（见<a href="/2020/08/20/docker-entrypoint-and-cmd/" title="Dockerfile 中的 ENTRYPOINT 和 CMD">上一篇博客</a>的描述）</p><h2 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><ul><li><a href="https://docs.docker.com/engine/reference/commandline/kill/" target="_blank" rel="noopener" title="docker kill | Docker Documentation">docker kill 官方文档</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/stop/" target="_blank" rel="noopener" title="docker stop | Docker Documentation">docker stop 官方文档</a></li><li><a href="https://www.cnblogs.com/ilinuxer/p/6188303.html" target="_blank" rel="noopener" title="理解Docker容器的进程管理">理解Docker容器的进程管理</a></li><li><a href="https://docs.servicecomb.io/java-chassis/zh_CN/general-development/shutdown/" target="_blank" rel="noopener" title="Java-Chassis 优雅停机">优雅停机</a></li></ul><h2 id="本文验证环境"><a href="#本文验证环境" class="headerlink" title="本文验证环境"></a>本文验证环境</h2><p>同<a href="/2020/08/20/docker-entrypoint-and-cmd/" title="Dockerfile 中的 ENTRYPOINT 和 CMD">Dockerfile 中的 ENTRYPOINT 和 CMD</a>。</p>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ServiceComb-Java-Chassis</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dockerfile 中的 ENTRYPOINT 和 CMD</title>
    <link href="undefined2020/08/20/docker-entrypoint-and-cmd/"/>
    <url>2020/08/20/docker-entrypoint-and-cmd/</url>
    
    <content type="html"><![CDATA[<p>关于 Dockerfile 中 ENTRYPOINT 和 CMD 的简要对比及使用说明</p><a id="more"></a><blockquote><p>在 Dockerfile 中， <code>ENTRYPOINT</code> 命令和 <code>CMD</code> 命令都可以指定 docker 容器启动时运行的命令，它们之间有什么异同，使用上又有什么需要注意的呢？</p></blockquote><h2 id="简要对比"><a href="#简要对比" class="headerlink" title="简要对比"></a>简要对比</h2><h3 id="ENTRYPOINT-命令和-CMD-命令都可用于指定-docker-容器启动时默认运行的命令，并且它们都是可以覆盖的"><a href="#ENTRYPOINT-命令和-CMD-命令都可用于指定-docker-容器启动时默认运行的命令，并且它们都是可以覆盖的" class="headerlink" title="ENTRYPOINT 命令和 CMD 命令都可用于指定 docker 容器启动时默认运行的命令，并且它们都是可以覆盖的"></a><code>ENTRYPOINT</code> 命令和 <code>CMD</code> 命令都可用于指定 docker 容器启动时默认运行的命令，并且它们都是可以覆盖的</h3><p><code>ENTRYPOINT</code> 命令可以使用 <code>--entrypoint</code> 参数覆盖。<br>如果可执行命令还需要加上参数，记得参数是加在末尾的。<br>例如，执行 <code>docker run --entrypoint sleep test 3600</code> 命令，表示启动一个 <code>test:latest</code> 镜像的容器，执行的命令效果是 <code>sleep 3600</code>（注意这里作为命令的 <code>sleep</code> 和作为参数的 <code>3600</code> 的位置不是连在一起的！）。</p><p><code>CMD</code> 命令不需要使用特别的参数覆盖，直接在 <code>docker run</code> 命令的末尾添加参数即可。<br>例如，执行 <code>docker run test sleep 3600</code> 命令，也表示启动一个 <code>test:latest</code> 镜像的容器，执行的命令是 <code>sleep 3600</code>。<br>（前提条件是镜像没有指定<code>ENTRYPOINT</code>，后文会展示 <code>ENTRYPOINT</code> 和 <code>CMD</code> 是可以共同生效的）</p><h3 id="如果你希望打出的镜像只执行某个具体的程序，那么-ENTRYPOINT-更适合用于指定启动命令"><a href="#如果你希望打出的镜像只执行某个具体的程序，那么-ENTRYPOINT-更适合用于指定启动命令" class="headerlink" title="如果你希望打出的镜像只执行某个具体的程序，那么 ENTRYPOINT 更适合用于指定启动命令"></a>如果你希望打出的镜像只执行某个具体的程序，那么 <code>ENTRYPOINT</code> 更适合用于指定启动命令</h3><p>如前文所述， <code>ENTRYPOINT</code> 指定的启动命令覆盖起来更麻烦一些。<br>该命令通常都是用于指定一个预设的启动命令的，用户一般不会修改此启动命令，但他们可能增加一些参数。<br>例如使用如下的 Dockerfile 打一个镜像：</p><pre><code class="Dockerfile">FROM alpineENTRYPOINT [&quot;ping&quot;]</code></pre><p>执行打包<code>docker build -t test -f Dockerfile .</code>。<br>则在运行 <code>test</code> 镜像时可以通过在 <code>docker run</code> 命令末尾追加参数来调整运行的<code>ping</code>命令。<br>例如可以执行 <code>docker run test localhost</code> 来运行 <code>ping localhost</code>，也可以执行 <code>docker run test www.baidu.com</code> 来运行 <code>ping www.baidu.com</code>。</p><h3 id="如果你希望打出的镜像更灵活，那么使用-CMD-更合适"><a href="#如果你希望打出的镜像更灵活，那么使用-CMD-更合适" class="headerlink" title="如果你希望打出的镜像更灵活，那么使用 CMD 更合适"></a>如果你希望打出的镜像更灵活，那么使用 <code>CMD</code> 更合适</h3><p>如前文所述，仅仅是在 <code>docker run</code> 命令的末尾添加参数即可覆盖 <code>CMD</code> 命令。<br>因此用户可以更加方便灵活地指定其他启动命令来运行镜像。</p><h2 id="命令书写风格：-shell-和-exec"><a href="#命令书写风格：-shell-和-exec" class="headerlink" title="命令书写风格： shell 和 exec"></a>命令书写风格： shell 和 exec</h2><p>在 Dockerfile 中，把启动命令写成 <code>ENTRYPOINT ifconfig</code> 和 <code>ENTRYPOINT [&quot;ifconfig&quot;]</code> 都是可以的，前者称为 shell 风格，后者称为 exec 风格，而且在运行 docker 镜像时看上去效果也一样。<br>但这两种写法打出的镜像中实际运行的启动命令并不相同。</p><p>使用 shell 风格的启动命令打出的镜像，会将 <code>ENTRYPOINT</code> 后面接的命令整体以 <code>/bin/sh -c</code> 的形式执行。<br>例如 Dockerfile 中写的是 <code>ENTRYPOINT ifconfig eth0</code> ，则打出的镜像中启动命令为 <code>/bin/sh -c &#39;ifconfig eth0&#39;</code>。</p><p>使用 exec 风格的启动命令打出的镜像，会将其中的命令分段拼接起来执行。<br>例如 Dockerfile 中写的是 <code>ENTRYPOINT [&quot;ifconfig&quot;, &quot;eth0&quot;]</code> ，则打出的镜像中启动命令为 <code>ifconfig eth0</code>。</p><p>直接执行这两种风格的 Dockerfile 打出的镜像，从效果上看似乎没有差别。<br>但是 shell 风格的写法会让 <code>docker run</code> 镜像时不好添加参数，而 exec 风格的写法则没有此问题。<br>因此，一般更推荐使用 exec 风格的写法书写 Dockerfile。</p><p>作为示例，我们分别以两种风格各书写一份 Dockerfile，内容如下：</p><ul><li><p>DockerfileShell:</p><pre><code class="Dockerfile">FROM alpineENTRYPOINT ifconfig</code></pre></li><li><p>DockerfileExec:</p><pre><code class="Dockerfile">FROM alpineENTRYPOINT [&quot;ifconfig&quot;]</code></pre></li></ul><p>分别执行 <code>docker build -t test-shell -f DockerfileShell .</code> 和 <code>docker build -t test-exec -f DockerfileExec .</code> 打出镜像。<br>可以先使用 <code>docker history</code> 观察镜像的差别：</p><pre><code class="shell"># docker history --no-trunc test-shellIMAGE                                                                     CREATED              CREATED BY                                                                                          SIZE                COMMENTsha256:3ff667ccad9ec9e5cdd1450bcfe9cd5463fc91c2ddd7f71221b6e65d20aa1eea   About a minute ago   /bin/sh -c #(nop)  ENTRYPOINT [&quot;/bin/sh&quot; &quot;-c&quot; &quot;ifconfig&quot;]                                           0Bsha256:a24bb4013296f61e89ba57005a7b3e52274d8edd3ae2077d04395f806b63d83e   2 months ago         /bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot;]                                                                  0B&lt;missing&gt;                                                                 2 months ago         /bin/sh -c #(nop) ADD file:c92c248239f8c7b9b3c067650954815f391b7bcb09023f984972c082ace2a8d0 in /    5.57MB# docker history --no-trunc test-execIMAGE                                                                     CREATED              CREATED BY                                                                                          SIZE                COMMENTsha256:e885515099ca3fa7cd55a40597f960f0660ea040dfe304888e12fedd3bec8748   About a minute ago   /bin/sh -c #(nop)  ENTRYPOINT [&quot;ifconfig&quot;]                                                          0Bsha256:a24bb4013296f61e89ba57005a7b3e52274d8edd3ae2077d04395f806b63d83e   2 months ago         /bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot;]                                                                  0B&lt;missing&gt;                                                                 2 months ago         /bin/sh -c #(nop) ADD file:c92c248239f8c7b9b3c067650954815f391b7bcb09023f984972c082ace2a8d0 in /    5.57MB</code></pre><p>无论是执行 <code>docker run --rm test-shell</code> 还是 <code>docker run --rm test-exec</code> 都会将容器中全部的网卡打印出来。<br>但如果我们指定打印 <code>eth0</code> 网卡的信息，两个容器的差异就会显现出来了：</p><ul><li><p>shell 风格：</p><pre><code class="shell"># docker run --rm test-shell eth0eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:03          inet addr:172.17.0.3  Bcast:172.17.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:90 (90.0 B)  TX bytes:0 (0.0 B)lo        Link encap:Local Loopback          inet addr:127.0.0.1  Mask:255.0.0.0          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:0 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</code></pre></li><li><p>exec 风格：</p><pre><code class="shell"># docker run --rm test-exec eth0eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:03          inet addr:172.17.0.3  Bcast:172.17.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:90 (90.0 B)  TX bytes:0 (0.0 B)</code></pre></li></ul><p>也就是说， shell 风格打出的镜像执行的命令类似于 <code>bash -c &#39;ifconfig&#39; eth0</code> ，结尾的 <code>eth0</code> 根本没有作为参数追加到 <code>ifconfig</code> 后面。<br>而 exec 风格打出的镜像，参数才能正确地追加到启动命令的后面，达到 <code>ifconfig eth0</code> 的效果。</p><h2 id="ENTRYPOING-和-CMD-联用"><a href="#ENTRYPOING-和-CMD-联用" class="headerlink" title="ENTRYPOING 和 CMD 联用"></a>ENTRYPOING 和 CMD 联用</h2><p><code>ENTRYPOINT</code> 和 <code>CMD</code> 命令联用，可以实现由 <code>ENTRYPOINT</code> 命令指定预设的应用程序启动命令，由 <code>CMD</code> 声明默认启动参数的效果。<br>我们用这样一份 Dockerfile 打出名为 <code>test</code> 的镜像：</p><pre><code class="Dockerfile">FROM alpineENTRYPOINT [&quot;ifconfig&quot;]CMD [&quot;lo&quot;]</code></pre><p>这样此镜像的启动程序就是 <code>ifconfig</code> 命令，默认的参数是用来显示本地回环地址的。而我们也可以通过在 <code>docker run</code> 命令后追加参数来打印其他网卡：<br>默认参数效果：</p><pre><code class="shell"># docker run --rm testlo        Link encap:Local Loopback          inet addr:127.0.0.1  Mask:255.0.0.0          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:0 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</code></pre><p>手动指定其他参数：</p><pre><code class="shell"># docker run --rm test eth0eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:03          inet addr:172.17.0.3  Bcast:172.17.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:90 (90.0 B)  TX bytes:0 (0.0 B)</code></pre><p>可以看到追加到命令末尾的 <code>eth0</code> 参数覆盖了 <code>CMD</code> 指定的默认参数 <code>lo</code> ，但是 <code>ENTRYPOINT</code> 指定的启动命令 <code>ifconfig</code> 是不变的。</p><p><strong>注意</strong>：要达到这种效果，<strong>必须以 exec 形式书写 <code>CMD</code> 和 <code>ENTRYPOINT</code> 命令</strong>，使用 shell 形式书写达不到效果的。</p><h2 id="本文验证环境："><a href="#本文验证环境：" class="headerlink" title="本文验证环境："></a>本文验证环境：</h2><ul><li><p>宿主机：Ubuntu 18.04</p></li><li><p>docker：</p><pre><code class="shell"># docker versionClient: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.4 Git commit:        e68fc7a Built:             Fri Oct 19 19:43:14 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       e68fc7a  Built:            Thu Sep 27 02:39:50 2018  OS/Arch:          linux/amd64  Experimental:     false</code></pre></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/30555962" target="_blank" rel="noopener">Dockerfile: ENTRYPOINT和CMD的区别</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>man page section 的打开方式</title>
    <link href="undefined2020/04/09/whats-linux-manpage-sections/"/>
    <url>2020/04/09/whats-linux-manpage-sections/</url>
    
    <content type="html"><![CDATA[<p>你知道 man page 后面的括号和数字是什么意思吗？</p><a id="more"></a><p>使用 Linux 的时候免不了会忘记某些命令的用法，这时候， man page ，或者说 <code>man</code> 命令就能帮助我们快速查找命令的正确使用姿势。但有时候，我们在 man page 里能看到命令后面带着括号和数字的内容，像是某种引用一样。比如，我们输入 <code>man sleep</code>，在 man page 开头能看到这样的内容：</p><pre><code class="Text">SLEEP(1)                         User Commands                        SLEEP(1)NAME       sleep - delay for a specified amount of time</code></pre><p>而在结尾的<code>SEE ALSO</code>部分，又能看到这样的内容：</p><pre><code class="Text">SEE ALSO       sleep(3)</code></pre><p>那么， <code>sleep(1)</code> 和 <code>sleep(3)</code> 有什么区别呢？而且，似乎我现在看的是 <code>sleep(1)</code> ，如果我想看 <code>sleep(3)</code>，我该怎么打开它呢？</p><p>其实我们查阅一下 <code>man</code> 命令自己的 man page 就能看到相关说明，括号加数字表示的是 man page 的 “section” ，不同 section 代表的含义如下：</p><pre><code class="Text">       1   Executable programs or shell commands       2   System calls (functions provided by the kernel)       3   Library calls (functions within program libraries)       4   Special files (usually found in /dev)       5   File formats and conventions eg /etc/passwd       6   Games       7   Miscellaneous  (including  macro  packages  and  conventions), e.g.           man(7), groff(7)       8   System administration commands (usually only for root)       9   Kernel routines [Non standard]</code></pre><p>所以一般我们查 Linux shell 命令时应该看的是 section 1 部分。当我们使用<code>man</code>命令时，系统会根据<code>1 n l 8 3 2 3posix 3pm 3perl 3am 5 4 9 6 7</code>的默认优先级顺序返回一个匹配上的 man page section 展示出来。</p><p>如果要看其他 section 的 man page ，打开方式有两种：</p><ul><li><code>man &lt;section&gt; &lt;cmd&gt;</code>，例如 <code>man 3 sleep</code></li><li><code>man &lt;cmd&gt;.&lt;section&gt;</code>，例如 <code>man sleep.3</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>运维能力</category>
      
    </categories>
    
    
    <tags>
      
      <tag>运维能力</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java-Chassis 2.0 新版本重大变更预览</title>
    <link href="undefined2020/01/03/java-chassis-2-0-major-feature-preview/"/>
    <url>2020/01/03/java-chassis-2-0-major-feature-preview/</url>
    
    <content type="html"><![CDATA[<p>Java-Chassis 2.0 版本发布前夕，解读新版本核心机制的变更。</p><a id="more"></a><h2 id="Java-Chassis与契约"><a href="#Java-Chassis与契约" class="headerlink" title="Java-Chassis与契约"></a>Java-Chassis与契约</h2><p>如果让我给出一个<a href="https://github.com/apache/servicecomb-java-chassis" target="_blank" rel="noopener">ServiceComb-Java-Chassis</a>与其他微服务框架最本质的区别，私以为不是handler、filter等扩展机制，也不是能够充分发挥Vert.x性能优势的Reactive模式，而是它以契约为中心的设计思想。</p><h3 id="基于契约的抽象模型"><a href="#基于契约的抽象模型" class="headerlink" title="基于契约的抽象模型"></a>基于契约的抽象模型</h3><p>Java-Chassis对OpenAPI契约的原生支持使其对于用户的服务接口的约束和掌握能力达到了一个比较高的水准，大家可以去看看Java-Chassis对于其<a href="https://docs.servicecomb.io/java-chassis/zh_CN/start/architecture.html" target="_blank" rel="noopener">框架架构</a>的描述，它可以将SpringMVC、JAX-RS、透明RPC三种服务端编程模型和RPC、RestTemplate两种客户端变成模型都归一化到OpenAPI契约上，在此基础上可以提供统一的运行模型（服务治理、负载均衡等）和通信模型（HTTP协议、highway协议），让治理和传输变成了与业务代码形态无关的公共能力。这一切都是Java-Chassis原生自带的，不需要用户再去手动集成任何其他的框架了。</p><p><img src="/img/blog/java-chassis-2-0-major-feature-preview/java-chassis-architecture.png" srcset="/img/loading.gif" alt=""></p><h3 id="强类型内核——运行时参数与契约声明完全一致"><a href="#强类型内核——运行时参数与契约声明完全一致" class="headerlink" title="强类型内核——运行时参数与契约声明完全一致"></a>强类型内核——运行时参数与契约声明完全一致</h3><p>我们还可以更进一步地设想一下，因为契约的存在，Java-Chassis是可以在运行模型中知道每个微服务有多少个接口，各个接口的url和参数，以及对象类型参数的内部详细字段信息的。因此如果用户想要基于Java-Chassis开发一些比较高阶的，需要依赖这些接口细节信息的治理逻辑，契约信息是可以让事情变得更简单的。<br>但要想做到比较理想化的状态，Java-Chassis需要确保运行时在框架里传输的参数类型确实是契约声明的参数类型。大家可以用Java-Chassis 1.3版本写个<a href="https://docs.servicecomb.io/java-chassis/zh_CN/edge/by-servicecomb-sdk.html" target="_blank" rel="noopener">EdgeService</a>网关服务，再写个后台demo服务做个实验。通常我们是不会在网关服务引用后端服务的接口jar包的，这也意味着网关服务的classpath里找不到后端服务的参数类型。但Java-Chassis会根据契约里面记录的信息（<code>x-java-class</code>字段）去搜索网关服务的classpath。<strong>如果在EdgeService网关服务里找不到这个参数类型（类名和包名得完全匹配上），框架会根据后端服务契约的记载去动态生成这样一个Java类型，以确保当请求经过EdgeService的运行模型时，里面的参数类型就是契约里面记录的类型。</strong>可以在EdgeService的handler链里面打个断点，比如打在<code>org.apache.servicecomb.core.Invocation#next</code>方法里，这里是handler链遍历执行的必经之路。关注一下<code>Invocation</code>的<code>getArgs</code>方法返回的对象数组，这里面按照后端服务契约的声明记录了请求参数。你会发现里面的参数顺序和类型都和契约里面记载的一模一样。<strong><em>这就是Java-Chassis所说的“强类型内核”——保证Java-Chassis框架里传输的参数数据是强类型的，与契约声明完全一致</em></strong>。</p><h3 id="促进系统接口规范性"><a href="#促进系统接口规范性" class="headerlink" title="促进系统接口规范性"></a>促进系统接口规范性</h3><p>此外，这种框架上的约束可以促使用户设计出更符合REST风格的微服务接口。虽然完成一份课程设计作业可能完全不需要你去关注服务的接口设计的好坏，但这在大型生产系统中却是一个要命的课题——大公司的IT系统通常都比较庞大，而且可能被划分为几个不同的系统交给不同的部门（或承包商）开发，这些系统之间有着各种交互逻辑。如果接口设计得太烂的话，要理解这些接口的行为都是个难题。随之而来的问题还有部门间沟通成本的提高：如果你想确定这么一个接口应该如何调用，最方便的方式当然是去找它的开发或者维护者当面询问了。但其实对于程序开发而言，语音交流是很低效的，而且信息得不到沉淀，有多少人要对接你的系统，你就会被询问多少次。至于接口文档？老实说一个团队都把代码维护到这个份上了，你也很难指望他们写的文档有多好，很大可能是文档已经完全过时，或者根本不存在。即使上头有整改的命令下来，让部门梳理接口文档，花大力气整出来的资料也很有可能在一段时间后再次陷入过时的状态……文档不存在你还知道找人问，文档要是过时了，会埋下多大坑呢？这个只能看你的运气了。<br>笔者曾经见识过不同公司、部门的业务系统，它们都免不了有一些放飞自我的接口……举个简单的例子，接口单一性原则很容易随着系统的膨胀而被打破。你以为只是往里面不停地加新参数吗？实际情况可能更糟糕！有些开发者使用的微服务开发框架具备多态序列化能力，也就是说他们可以把微服务接口参数定义为一个抽象类、接口或者Object，然后让业务代码根据实际传入参数的类型来判断执行哪种业务逻辑。这种代码一旦出现问题你很难分析，找开发都没用，搞不好开发已经换过几批了，这个时候程序的行为只有在运行起来时才能知道，你已经无法通过走读代码分析业务系统的逻辑了。BTW，一些使用Servlet开发风格的旧系统通常也会有类似的问题。<br>等到你发现这个系统已经没救了的时候……你也只能捏着鼻子忍下来，否则一堆人会找你反馈接口兼容性问题。在很多业务场景下，维持对外接口的兼容性是更加不能触犯的原则。<br><strong>要想解决这个问题，成本最低的方式当然是从源头下手</strong>，一开始就别写烂接口，就不会有那么多的幺蛾子了。Java-Chassis要原生支持OpenAPI规范的契约，就要求用户写出形式上足够规范的接口，否则服务启动就会在<a href="https://docs.servicecomb.io/java-chassis/zh_CN/build-provider/code-first.html" target="_blank" rel="noopener" title="使用隐式契约">框架自动生成契约</a>的时候报错。接口形式上没什么大问题，写出烂接口的可能性自然也会降低了。天生自带一份Swagger契约文档的框架也可以让开发人员在跟其他部门的人打交道的时候少费些口舌，与代码同源的接口文档在可信度上也比手写的文档要高得多。</p><h2 id="硬币的反面"><a href="#硬币的反面" class="headerlink" title="硬币的反面"></a>硬币的反面</h2><p>然而成也萧何败萧何，Java-Chassis这种基于契约的设计虽然给内部各组件的归一化设计带来了诸多便利，也让它的治理扩展能力有更多的遐想空间，但是它确实对用户的接口设计多了一些限制。据我观察，这也是大部分用户上手Java-Chassis的最大难点。此外还有两点比较容易被人诟病。</p><h3 id="网关转发接口行为变化"><a href="#网关转发接口行为变化" class="headerlink" title="网关转发接口行为变化"></a>网关转发接口行为变化</h3><p>Java-Chassis的这一强类型内核也让框架的行为在某些场景下变得有些令人迷惑。举个例子，部分用户可能在后端服务接口参数里面做一些特别的设置，像是在属性声明的时候给一个默认值，如下：</p><pre><code class="java">public class Person {  // 给name属性赋一个默认值&quot;Bob&quot;  private String name = &quot;Bob&quot;;  // getter/setter &amp; toString omitted}</code></pre><p>微服务接口逻辑如下：</p><pre><code class="java">  @PostMapping(path = &quot;/greeting&quot;)  public String greeting(@RequestBody Person person) {    return &quot;Hello, &quot; + person.getName();  }</code></pre><p>在直接调用后端服务接口时一切看上去都是符合预期的：</p><ul><li><p>带name调用接口：</p><pre><code>&gt; $ curl -XPOST -H &#39;Content-Type: application/json&#39; \&gt; &#39;http://localhost:8080/provider/v0/greeting&#39; \&gt; -d &#39;{&quot;name&quot;:&quot;Alice&quot;}&#39;&quot;Hello, Alice&quot;</code></pre></li><li><p>不带name调用接口：</p><pre><code>&gt; $ curl -XPOST -H &#39;Content-Type: application/json&#39; \&gt; &#39;http://localhost:8080/provider/v0/greeting&#39; \&gt; -d &#39;{}&#39;&quot;Hello, Bob&quot;</code></pre></li></ul><p>但如果通过EdgeService网关服务调用后端服务，效果就不是这样了：</p><pre><code>&gt; $ curl -XPOST -H &#39;Content-Type: application/json&#39; \&gt; &#39;http://localhost:8000/rest/provider/v0/greeting&#39; \&gt; -d &#39;{}&#39;&quot;Hello, null&quot;</code></pre><p>也许你已经意识到问题出在哪里了：<em>EdgeService网关是没有依赖后端服务的接口jar包的，在classpath中找不到<code>Person</code>类的情况下，Java-Chassis会根据后端服务契约的描述动态生成一个<code>Person</code>类。框架生成的<code>Person</code>类只会有契约所声明的属性及其getter/setter方法（也就是标准的Java Bean），至于用户在后端服务写的属性初始化赋值代码，框架当然是不知道的。</em>所以在EdgeService网关里，<code>Person</code>类大概长这样：</p><pre><code class="java">public class Person {  private String name;  public String getName() {    return name;  }  public void setName(String name) {    this.name = name;  }}</code></pre><p>EdgeService转发给后端的body也就变了，它接到的请求body是<code>{}</code>，但在EdgeService内部的运行模型经历一轮反序列化和序列化后，转发给后端服务的body是<code>{&quot;name&quot;:null}</code>这样的。</p><p>类似的场景还有在后端服务接口参数上打上Jackson的相关注解来修改参数的序列化行为等。</p><blockquote><p>这个现象也不好说是Java-Chassis的问题，因为定义微服务接口的时候最好是不要让自己的接口依赖于“空”值或者<code>null</code>值这种概念，否则很容易出问题。不过现象确实有点反直觉，不少人以为框架里面传的是像<code>String</code>或者<code>byte[]</code>这种类型的原始json串，但实际上却不是这样。</p></blockquote><h3 id="潜在的性能问题"><a href="#潜在的性能问题" class="headerlink" title="潜在的性能问题"></a>潜在的性能问题</h3><p>在一些旧系统改造为微服务的项目里，第一步通常是把一个单体系统切换到使用Java-Chassis开发，此时的一个“微”服务通常很大，单个服务有着大量的接口和参数定义。对于后端服务之间的调用场景可能还好，因为客户端服务一般会引入服务端的接口定义jar包，不需要客户端在加载服务端契约的时候去动态生成Java类型了。而对于EdgeService网关而言，每加载一个版本的后端服务契约，就需要生成大量的动态Java类（Java-Chassis 1.x版本是一个微服务版本对应一个<code>ClassLoader</code>实例的）。由于客户端，无论是普通的后端服务还是EdgeService，都需要将一个微服务版本的契约一次性完全加载完成才能做调用，服务接口太多的话加载会很消耗时间。<br>某些用户在使用EdgeService时还会长时间运行不升级不重启，<code>ClassLoader</code>实例太多了占用的内存也会变多，最终导致EdgeService网关的堆内存消耗殆尽，系统响应变慢甚至OOM，要解决这种问题只能重启微服务实例。</p><h2 id="Java-Chassis-2-0：弱类型内核"><a href="#Java-Chassis-2-0：弱类型内核" class="headerlink" title="Java-Chassis 2.0：弱类型内核"></a>Java-Chassis 2.0：弱类型内核</h2><p>为了改进强类型内核方案下Java-Chassis的使用不便，ServiceComb-Java-Chassis开发团队对Java-Chassis的核心机制进行了一番重构，为了区别于旧版本，新版本的Java-Chassis被称为“弱类型内核”版本。</p><blockquote><p>强类型内核版本对应于Java-Chassis的<a href="https://github.com/apache/servicecomb-java-chassis/tree/1.3.x" target="_blank" rel="noopener">1.3.x分支</a>，版本是 1.3.x。弱类型内核版本对应于Java-Chassis的<a href="https://github.com/apache/servicecomb-java-chassis/tree/master" target="_blank" rel="noopener">master分支</a>，版本是 2.0。<br><em>注意，这里讨论的场景是REST传输方式。</em></p></blockquote><h3 id="核心原理变更"><a href="#核心原理变更" class="headerlink" title="核心原理变更"></a>核心原理变更</h3><p>在2.0版本中，consumer端服务在加载provider端微服务契约时仍然会根据<code>x-java-class</code>字段去classpath里查找是否有现成的类型，如果找得到则仍然沿用找到的参数类型；<strong>找不到声明的参数类型时，框架不会根据契约描述去动态生成参数Java类型，而是依赖Jackson的反序列化能力尝试将其转换为<code>Object</code>类型数据。实际得到的参数值，依照原始json串的格式，可能是<code>LinkedHashMap</code>/<code>String</code>/primitive type等。</strong>使用过Jackson的朋友可以把这看成是<code>ObjectMapper</code>的原生能力，指定将json串反序列化为<code>Object</code>类型。也就是说，Java-Chassis减弱了契约对于运行时实际参数类型的约束力，以此得到了更好的契约加载性能、更小的内存占用量，以及某些使用场景下更符合“直觉”的使用体验。</p><p>对于后端微服务之间的调用场景，如果consumer端加载了provider端的接口jar包，那么从1.3版本升级到2.0版本可能对性能和内存占用没有多大的影响。而对于EdgeService调用后端服务，或者consumer端使用的参数类型与provider端声明的不一致（总之就是consumer端的classpath里找不到provider声明的参数类型）的场景，由于consumer端不再根据契约动态生成参数和接口类型，加载服务端契约的耗时和内存消耗量都会减少——契约对于consumer端的框架而言更像是一份“参考文档”了。</p><p>除此之外，EdgeService网关的请求转发行为看上去也更像是原样转发了。还是以上文所举的场景为例，如果发给网关的请求body是<code>{}</code>，那么EdgeService会将其反序列化为一个空的<code>LinkedHashMap</code>，经过其内部的handler链再转发给后端服务，后端服务接收到的请求body仍然是<code>{}</code>。</p><p>对于一些特别的场景，例如基于Java-Chassis二次开发业务调用系统，请求转发和调用操作很可能是使用通用逻辑统一执行的，代码形式与普通业务代码不同。由于强类型内核要求传参类型与契约声明一致，在实现的复杂度上会高一些。而对于弱类型内核而言，使用LinkedHashMap等类型传参也是可以的，不强制要求加载契约声明的参数类型，实现起来会更容易。</p><h3 id="升级兼容性"><a href="#升级兼容性" class="headerlink" title="升级兼容性"></a>升级兼容性</h3><p>目前看来，Java-Chassis从1.3升级到2.0版本的主要变更在于传输方面的内部逻辑，从用户体验上来看区别不大。<br>如果系统使用Java-Chassis的方式比较常规，那么升级时碰到不兼容问题的概率就比较小，可能需要注意的地方包括，在EdgeService的handler、filter里面拿到的<code>Invocation</code>携带的REST请求参数和返回值的类型会有变化。<br>如果业务系统以深度定制的方式使用了Java-Chassis，那么在升级过程中可能会发现一些底层的类、方法的变动。</p><p>在新旧版本混用的问题上，对于REST传输方式，因为其底层传输实现是HTTP协议+json格式body体，新旧版本的Java-Chassis在这方面的实现都是符合业界标准的，可以将基于不同版本的Java-Chassis开发的微服务组合在一起相互调用。但对于highway传输方式，目前来看highway会进行重新的设计和实现，因此2.0版本和1.x版本的Java-Chassis无法以highway的方式互相调用。</p>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ServiceComb</tag>
      
      <tag>microservice</tag>
      
      <tag>Java-Chassis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Jar包内容读取和修改的技巧</title>
    <link href="undefined2019/12/29/jar-file-inspect-and-modify-skill/"/>
    <url>2019/12/29/jar-file-inspect-and-modify-skill/</url>
    
    <content type="html"><![CDATA[<p>一些Linux上关于Jar包的实用小技巧</p><a id="more"></a><p>有过Linux服务器上Java问题定位经验的同学恐怕都碰到过一些疑难杂症问题，有些时候我们免不了会有把jar包打开看看的想法，以便检查一下里面的内容是不是真的如自己在本地环境里看到的那样。本文介绍了一些比较实用的方法，可以在Linux服务器环境达到这种效果 : )</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>为了演示下文的内容，先使用maven创建工程，把可执行jar包打出来。</p><p>先找个空目录，执行maven创建空工程的命令：</p><pre><code class="shell">mvn archetype:generate -DgroupId=test -DartifactId=demo -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false</code></pre><p>在当前目录下就会出现一个名为demo的目录，里面就是创建出来的新工程了，进入demo目录内，编辑pom文件，在里面加入打可执行jar包所需的插件配置，如下：</p><pre><code class="xml">  &lt;build&gt;    &lt;plugins&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;        &lt;version&gt;3.1&lt;/version&gt;        &lt;configuration&gt;          &lt;compilerArgument&gt;-parameters&lt;/compilerArgument&gt;          &lt;encoding&gt;UTF-8&lt;/encoding&gt;          &lt;source&gt;1.8&lt;/source&gt;          &lt;target&gt;1.8&lt;/target&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;        &lt;version&gt;2.10&lt;/version&gt;        &lt;executions&gt;          &lt;execution&gt;            &lt;id&gt;copy-dependencies&lt;/id&gt;            &lt;phase&gt;package&lt;/phase&gt;            &lt;goals&gt;              &lt;goal&gt;copy-dependencies&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;              &lt;outputDirectory&gt;target/lib&lt;/outputDirectory&gt;            &lt;/configuration&gt;          &lt;/execution&gt;        &lt;/executions&gt;      &lt;/plugin&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;        &lt;version&gt;2.6&lt;/version&gt;        &lt;configuration&gt;          &lt;archive&gt;            &lt;manifest&gt;              &lt;addClasspath&gt;true&lt;/addClasspath&gt;              &lt;classpathPrefix&gt;./lib/&lt;/classpathPrefix&gt;              &lt;mainClass&gt;test.App&lt;/mainClass&gt;              &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt;              &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt;            &lt;/manifest&gt;            &lt;manifestEntries&gt;              &lt;Class-Path&gt;.&lt;/Class-Path&gt;            &lt;/manifestEntries&gt;          &lt;/archive&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;  &lt;/build&gt;</code></pre><p>这里配置了三个插件，<code>maven-compiler-plugin</code>指定使用1.8的Java版本进行编译构建，使用<code>UTF-8</code>编码，并且编译后的方法参数名为源码中定义的参数名。<code>maven-dependency-plugin</code>用于将本工程所依赖的所有jar包复制到<code>target/lib</code>目录下。<code>maven-jar-plugin</code>插件用于打包，它指定了<code>test.App</code>作为jar包的main启动类，将<code>target/lib</code>目录下的第三方依赖jar包逐个加入到可执行jar包的classpath中，并且额外将可执行jar包所在目录（<code>.</code>目录）也加入到classpath中了。</p><p>maven自动生成的工程已经在<code>App</code>类里面打印了一句“Hello World!”了：</p><pre><code class="java">package test;/** * Hello world! * */public class App{    public static void main( String[] args )    {        System.out.println( &quot;Hello World!&quot; );    }}</code></pre><p>我们把<code>App</code>类复制为<code>App2</code>类：</p><pre><code class="shell">/tmp/jarfile/demo/src/main/java/test# cp App.java App2.java/tmp/jarfile/demo/src/main/java/test# ls -ltotal 8-rw-r--r-- 1 root root 180 Dec 29 16:30 App2.java-rw-r--r-- 1 root root 167 Dec 29 15:37 App.java</code></pre><p>把修改一下<code>App2</code>类的内容：</p><pre><code class="java">package test;/** * Hello world! * */public class App2{    public static void main( String[] args )    {        System.out.println( &quot;Hello World! - from App2&quot; );    }}</code></pre><p>然后在这个工程中执行<code>mvn clean package</code>把可执行jar包打出来。此时target目录里大概是这样的：</p><pre><code class="shell">/tmp/jarfile/demo/target# lltotal 44drwxr-xr-x 10 root root 4096 Dec 29 16:02 ./drwxr-xr-x  4 root root 4096 Dec 29 16:02 ../drwxr-xr-x  3 root root 4096 Dec 29 16:02 classes/-rw-r--r--  1 root root 2475 Dec 29 16:02 demo-1.0-SNAPSHOT.jardrwxr-xr-x  3 root root 4096 Dec 29 16:02 generated-sources/drwxr-xr-x  3 root root 4096 Dec 29 16:02 generated-test-sources/drwxr-xr-x  2 root root 4096 Dec 29 16:02 lib/drwxr-xr-x  2 root root 4096 Dec 29 16:02 maven-archiver/drwxr-xr-x  3 root root 4096 Dec 29 16:02 maven-status/drwxr-xr-x  2 root root 4096 Dec 29 16:02 surefire-reports/drwxr-xr-x  3 root root 4096 Dec 29 16:02 test-classes/</code></pre><p><code>demo-1.0-SNAPSHOT.jar</code>就是打出来的可执行jar包了。执行<code>java -jar demo-1.0-SNAPSHOT.jar</code>，由于我们在<code>maven-jar-plugin</code>插件中指定的main类是<code>test.App</code>，所以可以看到控制台输出的是”Hello World!”：</p><pre><code class="shell">/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!</code></pre><p>可执行jar包就打好了，准备工作完成~</p><blockquote><p>这种打法把第三方依赖包放在单独的lib目录里了，也有其他的打包方式可以把依赖jar打到可执行jar包内（如Spring Boot自带的jar包打包插件）。</p></blockquote><h2 id="查看和修改Jar包内容的方法"><a href="#查看和修改Jar包内容的方法" class="headerlink" title="查看和修改Jar包内容的方法"></a>查看和修改Jar包内容的方法</h2><p><strong>注意</strong>: 下文的每一小节都是独立的内容。为防止修改jar包的操作影响后文的效果，本文假设每一小节都是基于上文“准备工作”打出来的jar包进行的，互相不影响文件内容。</p><h3 id="使用vim"><a href="#使用vim" class="headerlink" title="使用vim"></a>使用vim</h3><p>使用vim命令也可以查看jar包的文件内容，就像打开普通的文本文件一样，输入<code>vim &lt;jar包名&gt;</code>，vim会展示jar包内的文件列表：</p><pre><code>&quot; zip.vim version v28&quot; Browsing zipfile /tmp/jarfile/demo/target/demo-1.0-SNAPSHOT.jar&quot; Select a file with cursor and press ENTERMETA-INF/META-INF/MANIFEST.MFtest/test/App.classtest/App2.classMETA-INF/maven/META-INF/maven/test/META-INF/maven/test/demo/META-INF/maven/test/demo/pom.xmlMETA-INF/maven/test/demo/pom.properties</code></pre><p>把光标移动到对应的行上敲回车，就可以打开这个文件看到它的内容了。</p><p>vim也可以编辑jar包内的文本文件，例如打开<code>META-INF/MANIFEST.MF</code>文件，将里面的”Main-Class”一行修改一下，把启动jar包的main类改为<code>App2</code>，如下：</p><pre><code>Manifest-Version: 1.0Implementation-Title: demoImplementation-Version: 1.0-SNAPSHOTArchiver-Version: Plexus ArchiverBuilt-By: rootSpecification-Title: demoImplementation-Vendor-Id: testClass-Path: .Main-Class: test.App2Created-By: Apache Maven 3.5.2Build-Jdk: 1.8.0_191Specification-Version: 1.0-SNAPSHOTImplementation-URL: http://maven.apache.org</code></pre><p>输入<code>:wq</code>命令保持并退出，跟我们编辑普通的文本文件一样操作。可能在将修改写入jar包并退出的时候会碰到报错，这种时候执行<code>:q!</code>命令强制退出就行了。再次执行<code>java -jar demo-1.0-SNAPSHOT.jar</code>可以看到此时打印的内容变成了”Hello World! - from App2”，说明对MANIFEST文件的修改生效了。</p><pre><code class="shell">## 基于源码打出来的原始jar包/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!## 使用vim修改manifest文件/tmp/jarfile/demo/target# vim demo-1.0-SNAPSHOT.jar## 再次执行jar包，可以看到修改生效了/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World! - from App2</code></pre><h3 id="使用unzip和zip命令"><a href="#使用unzip和zip命令" class="headerlink" title="使用unzip和zip命令"></a>使用unzip和zip命令</h3><p>jar包，其实是zip包（不是tar包呢……）。所以如果想要看zip中的内容，可以直接把jar包当zip包解压开来看看，像这样：</p><pre><code class="shell">/tmp/jarfile/demo/target# unzip demo-1.0-SNAPSHOT.jar -d extracted/Archive:  demo-1.0-SNAPSHOT.jar   creating: extracted/META-INF/  inflating: extracted/META-INF/MANIFEST.MF   creating: extracted/test/  inflating: extracted/test/App.class  inflating: extracted/test/App2.class   creating: extracted/META-INF/maven/   creating: extracted/META-INF/maven/test/   creating: extracted/META-INF/maven/test/demo/  inflating: extracted/META-INF/maven/test/demo/pom.xml  inflating: extracted/META-INF/maven/test/demo/pom.properties</code></pre><p>所有的文件都被解压到<code>extract</code>目录中了。如果只是想看看jar包里面有什么文件，也可以加上<code>-l</code>参数，不解压只是把文件内容都列出来：</p><pre><code class="shell">/tmp/jarfile/demo/target# unzip -l demo-1.0-SNAPSHOT.jarArchive:  demo-1.0-SNAPSHOT.jar  Length      Date    Time    Name---------  ---------- -----   ----        0  2019-12-29 16:32   META-INF/      374  2019-12-29 16:32   META-INF/MANIFEST.MF        0  2019-12-29 16:32   test/      553  2019-12-29 16:32   test/App.class      568  2019-12-29 16:32   test/App2.class        0  2019-12-29 16:32   META-INF/maven/        0  2019-12-29 16:32   META-INF/maven/test/        0  2019-12-29 16:32   META-INF/maven/test/demo/     2311  2019-12-29 16:02   META-INF/maven/test/demo/pom.xml      107  2019-12-29 16:32   META-INF/maven/test/demo/pom.properties---------                     -------     3913                     10 files</code></pre><p>然后只解压特定的文件内容：</p><pre><code class="shell">/tmp/jarfile/demo/target# unzip -l demo-1.0-SNAPSHOT.jar | grep MANIF      374  2019-12-29 17:08   META-INF/MANIFEST.MF/tmp/jarfile/demo/target# unzip demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MFArchive:  demo-1.0-SNAPSHOT.jar  inflating: META-INF/MANIFEST.MF/tmp/jarfile/demo/target# ll META-INF/MANIFEST.MF-rw-r--r-- 1 root root 374 Dec 29 17:08 META-INF/MANIFEST.MF</code></pre><p>我们可以把MANIFEST文件编辑一下，把启动类改为<code>App2</code>：<code>sed -i &#39;s/App/App2/&#39; META-INF/MANIFEST.MF</code>。</p><p>然后使用zip命令把修改后的文件替换回jar包中：<code>zip -u demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MF</code>。<code>-u</code>命令是把磁盘上的文件更新到jar包内，磁盘文件还是保留着的。也可以使用<code>-m</code>命令，把文件移动到jar包内，磁盘文件也就随之被删除了。</p><p>再次执行jar包可以看到文件修改已经生效了。</p><p>全流程如下：</p><pre><code class="shell">## 打包，进入target目录执行jar包查看效果/tmp/jarfile/demo# mvn clean package 2&gt;&amp;1 1&gt;/dev/null/tmp/jarfile/demo# cd target//tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!## 解压出manifest文件/tmp/jarfile/demo/target# unzip demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MFArchive:  demo-1.0-SNAPSHOT.jar  inflating: META-INF/MANIFEST.MF## 修改manifest文件的内容/tmp/jarfile/demo/target# sed -i &#39;s/App/App2/&#39; META-INF/MANIFEST.MF## 将修改后的manifest更新到jar包中/tmp/jarfile/demo/target# zip -u demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MFupdating: META-INF/MANIFEST.MF        zip warning: Local Entry CRC does not match CD: META-INF/MANIFEST.MF (deflated 42%)## 再次执行jar包可以看到修改生效了/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World! - from App2</code></pre><h3 id="使用jar命令"><a href="#使用jar命令" class="headerlink" title="使用jar命令"></a>使用jar命令</h3><p>既然是jar包，当然也可以使用<code>jar</code>命令来进行处理了。这个看上去最“正统”的命令之所以被排到最后，是因为很多时候我们所面对的环境里根本没有安装jdk，所以只能使用前面那些相对“偏门”的方法了。（看看孩子都被逼成啥样儿了！）</p><p><code>jar</code>命令可以用来创建、解压、更新jar包，这里只讲一点简单的。</p><ul><li><p><code>jar</code>命令有些用法和<code>tar</code>命令类似，使用<code>jar tf &lt;jar包名&gt;</code>命令可以查看jar包内的文件列表，也可以再加个<code>-v</code>参数获取更详细的信息。</p></li><li><p>使用<code>jar xf &lt;jar包名&gt; &lt;jar包内文件路径&gt;</code>命令可以将特定的文件解压出来。<strong>注意</strong>：解压和更新文件的时候文件路径都是相对的，相对于jar包内根目录和磁盘上的当前目录。</p></li><li><p>使用<code>jar uf &lt;jar包名&gt; &lt;文件路径&gt;</code>命令可以把特定文件更新到jar包内。</p><p><strong>注意</strong>：单纯的<code>-u</code>参数可以修改jar包内的普通文件（配置、<code>.class</code>文件等），但是修改不了MANIFEST文件。要修改MANIFEST还需要加上<code>-m</code>参数，像这样：<code>jar ufm demo-1.0-SNAPSHOT.jar MANIFEST.MF</code>（注意<code>-m</code>参数在<code>-f</code>参数的后面，否则会报错！），由于磁盘上的MANIFEST文件的部分配置项的key与jar包内MANIFEST有重复，你可能还会看到一大堆的告警信息。</p></li></ul><p>例子：</p><pre><code class="shell">## 重新打包/tmp/jarfile/demo# mvn clean package 2&gt;&amp;1 1&gt;/dev/null/tmp/jarfile/demo# cd target//tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!## 查看jar包内容/tmp/jarfile/demo/target# jar tf demo-1.0-SNAPSHOT.jarMETA-INF/META-INF/MANIFEST.MFtest/test/App.classtest/App2.classMETA-INF/maven/META-INF/maven/test/META-INF/maven/test/demo/META-INF/maven/test/demo/pom.xmlMETA-INF/maven/test/demo/pom.properties## 解压出manifest文件/tmp/jarfile/demo/target# jar xf demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MF## 把入口类改成test.App2/tmp/jarfile/demo/target# sed -i &#39;s/App/App2/&#39; META-INF/MANIFEST.MF## 把新的manifest文件更新到jar包内，忽略告警信息/tmp/jarfile/demo/target# jar uvfm demo-1.0-SNAPSHOT.jar META-INF/MANIFEST.MF 2&gt;/dev/nullupdated manifest## 再次执行jar包，可以看到结果已经变了/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World! - from App2</code></pre><h2 id="命令行编译class文件并更新到jar包内"><a href="#命令行编译class文件并更新到jar包内" class="headerlink" title="命令行编译class文件并更新到jar包内"></a>命令行编译class文件并更新到jar包内</h2><p>也许有的时候我们还需要临时修改一下某些类，比如为了获取定位问题的辅助信息多打点日志什么的。这个时候我们还需要修改源代码重新打包。但如果开发环境和程序部署环境是相互隔离的，而且部署环境恰好有jdk，我们也可以命令行手动编译class文件更新到jar包内。</p><p>作为例子，我们先在target目录里面创建一份<code>App</code>类的源码（注意目录结构与package声明的一致）：</p><pre><code class="shell">/tmp/jarfile/demo# mvn clean package 2&gt;&amp;1 1&gt;/dev/null/tmp/jarfile/demo# cd target/root@desktop-0023:/tmp/jarfile/demo/target# mkdir testroot@desktop-0023:/tmp/jarfile/demo/target# vim test/App.javaroot@desktop-0023:/tmp/jarfile/demo/target# cat test/App.javapackage test;public class App{    public static void main( String[] args )    {        System.out.println( &quot;Hello World!&quot; );        App2.main( args );    }}</code></pre><p>这里我们在<code>App</code>类里面调用了<code>App2#main</code>方法，所以<code>App</code>类是依赖<code>App2</code>类的。此时就不能直接使用<code>javac &lt;java源文件&gt;</code>的方式编译了，会报依赖找不到的错误：</p><pre><code class="shell">root@desktop-0023:/tmp/jarfile/demo/target# javac test/App.javatest/App.java:8: error: cannot find symbol        App2.main( args );        ^  symbol:   variable App2  location: class App1 error</code></pre><p>还需要用<code>-cp</code>参数指定一下依赖：</p><pre><code class="shell">## 更新jar包前root@desktop-0023:/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!## 指定 demo-1.0-SNAPSHOT.jar 为classpath，编译App.java所需的依赖在这个jar里面有root@desktop-0023:/tmp/jarfile/demo/target# javac -cp demo-1.0-SNAPSHOT.jar test/App.java## 更新jar包内的App.class文件root@desktop-0023:/tmp/jarfile/demo/target# jar uvf demo-1.0-SNAPSHOT.jar test/App.classadding: test/App.class(in = 450) (out= 309)(deflated 31%)## 运行更新后的jar包root@desktop-0023:/tmp/jarfile/demo/target# java -jar demo-1.0-SNAPSHOT.jarHello World!Hello World! - from App2</code></pre><p>此时jar包的执行逻辑已经被我们新编辑的<code>App.java</code>源码修改了。</p><hr><p>Banner图源：Photo on <a href="https://visualhunt.com/re6/5296d2aa" target="_blank" rel="noopener">VisualHunt.com</a></p>]]></content>
    
    
    <categories>
      
      <category>运维能力</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>运维能力</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>给Hexo + Github pages搭建的个人博客绑定域名</title>
    <link href="undefined2019/12/21/github-pages-bind-domain-name-solutions/"/>
    <url>2019/12/21/github-pages-bind-domain-name-solutions/</url>
    
    <content type="html"><![CDATA[<p>最近给博客绑定了域名，趁着还记得一些细节的时候把关键点都写下来 : )</p><a id="more"></a><h1 id="给Hexo-Github-pages搭建的个人博客绑定域名"><a href="#给Hexo-Github-pages搭建的个人博客绑定域名" class="headerlink" title="给Hexo + Github pages搭建的个人博客绑定域名"></a>给Hexo + Github pages搭建的个人博客绑定域名</h1><p>前段时间使用<a href="https://github.com/hexojs/hexo" target="_blank" rel="noopener">Hexo</a>给自己搭了一个博客，托管在Github上面。不过托管在Github上的博客对外暴露的是<code>github.io</code>的子域名，最近我又买了一个独立的域名绑定在这个博客上，看上去更顺眼了一些 ; )</p><p>给自己的博客绑定域名有什么好处呢？个人认为最大的好处应该是让我们的博客在网上有一个独立的入口了，这个入口不依赖于其他的实现。这个类似于面向对象编程里面接口和实现的关系。域名就是接口，用户通过域名访问我们的博客时可以不用在意我们把博客托管在哪个服务器上，而我们在Github pages上托管博客的域名，如<code>yhs0092.github.io</code>，就是具体的实现。<br>假设我们觉得从国内访问Github pages太慢了，还可以在国内另外找个服务器托管一份博客，可以把国内访问者的流量导流到国内的这个服务器上，加速访问过程。如果我们想把自己的博客迁移到另外一个地方了，或者某个服务器坏掉了，我们也可以很方便地做服务器地址切换。这些操作对于访问者来说都是无感知的。<br>除此之外，听说有个独立的域名对于搜索引擎爬取我们的博客内容也有好处，不过这个也取决于你买到的域名好不好。</p><h2 id="购买域名"><a href="#购买域名" class="headerlink" title="购买域名"></a>购买域名</h2><p>选择域名也是一个技术活，建议大家在下单购买自己中意的域名之前，先去检查一下这个域名之前有没有被人使用过，以及这个域名是否被各个搜索引擎ban掉了，这里的门道比较多，我刚刚开始接触，也是在网上搜资料看的，这里就不多说了，建议大家直接搜资料看看 ; )</p><p>这里是在华为云上购买的域名，进入华为云的域名注册服务，可以选一个中意的域名，先搜一下看看哪些后缀的域名还没有被占用。例如搜索一下“seatime”域名，可以看到部分顶级域名下的“seatime”二级域名已经被注册了。<br><img src="/img/blog/github-pages-bind-domain-name-solutions/search_for_available_domainnames.jpg" srcset="/img/loading.gif" alt=""><br>于是只能在还没有人使用的域名里选购一个了（先检查一下这个域名有没有被ban过！）。假设我们购买的是<code>seatime.online</code>，将其加入清单，然后购买，这样域名就到手了。</p><p><strong>注意</strong>： 在国内购买域名需要实名认证才能使用</p><h2 id="配置域名解析记录"><a href="#配置域名解析记录" class="headerlink" title="配置域名解析记录"></a>配置域名解析记录</h2><p>买到的域名还需要配置一下才能指向我们的Github pages地址。从华为云DNS服务的公网域名列表中找到刚刚购买的域名，点击右边的“解析”，进入配置页。<br><img src="/img/blog/github-pages-bind-domain-name-solutions/domain_name_config_entry.jpg" srcset="/img/loading.gif" alt=""><br>点击右上角的“添加记录集”，将之前搭建的Github pages地址填进去，如下图所示。注意这里选择的类型是<code>CNAME</code>，不同类型的记录功能各不相同，有兴趣的同学可以去搜一些资料了解一下。<br><img src="/img/blog/github-pages-bind-domain-name-solutions/add_dns_record.jpg" srcset="/img/loading.gif" alt=""><br>然后等待一段时间，你就能通过<code>seatime.online</code>解析到<code>yhs0092.github.io</code>的地址了。</p><h2 id="配置CNAME文件"><a href="#配置CNAME文件" class="headerlink" title="配置CNAME文件"></a>配置CNAME文件</h2><p>DNS配置生效后，新购买的域名就已经指向Github pages页面地址了。但此时如果去访问这个域名的话，得到的是Github的404返回页，这是因为我们还没有在Github pages中配置域名。我们还需要在工程的根目录下放置一份CNAME文件指向我们的域名。<br>这里说的“根目录”是指的托管在Github pages上的静态页面工程的根目录，而对于hexo源工程而言，CNAME文件应该放在<code>source/</code>目录下，文件内容就是我们的域名，如下：</p><pre><code>$ cat source/CNAMEseatime.online</code></pre><p>然后执行 <code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code> 完成构建和部署就行了。</p>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>web</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【转载】CSEJavaSDK重试和隔离如何判断错误？</title>
    <link href="undefined2019/12/17/java-chassis-circuitbreaker-isolate-counter-logic/"/>
    <url>2019/12/17/java-chassis-circuitbreaker-isolate-counter-logic/</url>
    
    <content type="html"><![CDATA[<p>mark一篇CSEJavaSDK熔断、隔离判断逻辑的帖子，同样适用于ServiceComb-Java-Chassis。</p><p>原文链接： <a href="https://bbs.huaweicloud.com/forum/thread-12790-1-1.html" target="_blank" rel="noopener">https://bbs.huaweicloud.com/forum/thread-12790-1-1.html</a></p><a id="more"></a><h1 id="技术交流-CSE重试和隔离如何判断错误？"><a href="#技术交流-CSE重试和隔离如何判断错误？" class="headerlink" title="[技术交流]CSE重试和隔离如何判断错误？"></a>[技术交流]CSE重试和隔离如何判断错误？</h1><blockquote><p>简单的描述：</p><ol><li>网络错误 + 503错误码等情况可以触发重试。</li><li>网络错误 + 503错误码 + 超时等错误可以触发隔离。</li></ol><p>细节内容可以参考代码。</p></blockquote><h2 id="负载均衡模块能力"><a href="#负载均衡模块能力" class="headerlink" title="负载均衡模块能力"></a>负载均衡模块能力</h2><p>LB模块具备请求重试和实例隔离能力。</p><ul><li>请求重试的条件参考<code>org.apache.servicecomb.loadbalance.DefaultRetryExtensionsFactory</code></li><li>实例隔离的条件参考<code>org.apache.servicecomb.loadbalance.LoadbalanceHandler#isFailedResponse</code></li><li>实例隔离状态恢复的逻辑参考<code>org.apache.servicecomb.loadbalance.filter.IsolationDiscoveryFilter#allowVisit</code></li><li>Java-Chassis定期ping机制会在某实例近期没有被调用时定时去检查其状态，该检查如果失败会产生和调用失败一样的错误计数，但是检查成功不会触发实例隔离恢复，相关逻辑在<code>org.apache.servicecomb.loadbalance.ServiceCombLoadBalancerStats#timer</code>的定时任务中。</li></ul><h2 id="熔断隔离模块能力"><a href="#熔断隔离模块能力" class="headerlink" title="熔断隔离模块能力"></a>熔断隔离模块能力</h2><p>CSE还提供了bizkeeper模块，这个模块集成了Hystrix的隔离仓等能力，这个隔离能力是针对微服务或者接口级别的，在实际业务系统中，发挥作用比较少。 这个模块也有判读错误条件：</p><ul><li>consumer: 490异常。比如网络操作、超时等。 参考<code>org.apache.servicecomb.bizkeeper.ConsumerBizkeeperCommand#isFailedResponse</code></li><li>provider: 590异常。比如业务处理抛出的未知RuntimeException等。 参考<code>org.apache.servicecomb.bizkeeper.ProviderBizkeeperCommand#isFailedResponse</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSE</tag>
      
      <tag>microservice</tag>
      
      <tag>ServiceComb-Java-Chassis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用keytool和OpenSSL自行签发TLS证书</title>
    <link href="undefined2019/11/13/CreateTLSCertificateByKeytoolAndOpenssl/"/>
    <url>2019/11/13/CreateTLSCertificateByKeytoolAndOpenssl/</url>
    
    <content type="html"><![CDATA[<p>本文主要说明如何使用JDK自带的keytool和OpenSSL自行签发TLS证书，方便进行本地开发测试。</p><a id="more"></a><h1 id="使用keytool和OpenSSL自行签发TLS证书"><a href="#使用keytool和OpenSSL自行签发TLS证书" class="headerlink" title="使用keytool和OpenSSL自行签发TLS证书"></a>使用keytool和OpenSSL自行签发TLS证书</h1><blockquote><p>本文适用于Java微服务场景下，自行创建CA和签发TLS证书，方便自行开发调试，不适合于生产条件。<br>最终目录结构：</p><pre><code>workdir    // 这是本文的工作目录，可以随意自定义|- ca      // CA证书所在目录（根证书）|- cert    // 服务端/客户端身份证书所在目录|- trust   // 信任证书所在目录</code></pre></blockquote><h2 id="基本说明"><a href="#基本说明" class="headerlink" title="基本说明"></a>基本说明</h2><p>创建一份证书，基本步骤有三步：</p><ol><li><p>创建一份自己的私钥文件</p><p>理论上讲这份私钥文件，必须保密，不能让其他人获取到内容的。</p></li><li><p>生成一份“证书请求文件”</p><p>生成证书请求文件的后缀一般是<code>.csr</code>(Certificate Signing Request)。<br>如果你要购买一份生产环境使用的TLS证书，就需要签一份csr文件发给CA，让他们根据你的csr文件签发证书给你。</p></li><li><p>签发证书</p><p>由于本文创建的证书只是用于开发、测试目的，所以不需要向CA购买证书，而是自行创建CA证书，再用CA证书签发TLS证书。</p></li></ol><p>在创建完TLS证书（身份证书）后，我们还可以使用JDK自带的<code>keytool</code>创建一份信任证书，这样可以让这套证书用于Java服务TLS对端认证的测试场景。</p><hr><p>环境信息：</p><ul><li>OpenJDK 1.8.0_191</li><li>OpenSSL 1.1.0g</li></ul><h2 id="创建CA"><a href="#创建CA" class="headerlink" title="创建CA"></a>创建CA</h2><p>跳转到 ca 目录下。由于是自己当CA签证书，所以要先创建好CA的证书。</p><h3 id="创建CA证书私钥"><a href="#创建CA证书私钥" class="headerlink" title="创建CA证书私钥"></a>创建CA证书私钥</h3><p>命令<code>openssl genrsa -aes128 -out ca.key 4096</code>表示以aes128加密的方式生成一个长度为4096bit的RSA私钥文件。<br><strong>注意</strong>：创建过程中<code>openssl</code>会让你输入私钥文件的密码，进行加密。</p><pre><code class="shell">workdir/ca# openssl genrsa -aes128 -out ca.key 4096Generating RSA private key, 4096 bit long modulus.............................................................................++.....................................++e is 65537 (0x010001)Enter pass phrase for ca.key:Verifying - Enter pass phrase for ca.key:workdir/ca# lltotal 12drwxr-xr-x 2 root root 4096 Nov 12 23:09 ./drwxr-xr-x 3 root root 4096 Nov 12 23:08 ../-rw------- 1 root root 3326 Nov 12 23:09 ca.key</code></pre><p>执行完成后当前目录下应该生成了一份<code>ca.key</code>文件，这份文件是私钥，应该保密存储。</p><h3 id="创建CA证书"><a href="#创建CA证书" class="headerlink" title="创建CA证书"></a>创建CA证书</h3><p>命令<code>openssl req -new -x509 -key ca.key -out ca.crt -days 3650</code> 的含义为，使用CA私钥（<code>-key ca.key</code>），创建一份CA证书（<code>-out ca.crt</code>），有效时间为3650天（<code>-days 3650</code>）。<br><strong>注意</strong>：这一步需要输入CA私钥文件的密码，即上一步创建<code>ca.key</code>文件时设置的密码。</p><pre><code class="shell">workdir/ca# openssl req -new -x509 -key ca.key -out ca.crt -days 3650Enter pass phrase for ca.key:You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#39;.&#39;, the field will be left blank.-----Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:GuangdongLocality Name (eg, city) []:ShenzhenOrganization Name (eg, company) [Internet Widgits Pty Ltd]:xxxOrganizational Unit Name (eg, section) []:xxxCommon Name (e.g. server FQDN or YOUR name) []:xxxEmail Address []:xxx@xxx.xxxworkdir/ca# lltotal 16drwxr-xr-x 2 root root 4096 Nov 12 23:21 ./drwxr-xr-x 3 root root 4096 Nov 12 23:08 ../-rw-r--r-- 1 root root 2069 Nov 12 23:21 ca.crt-rw------- 1 root root 3326 Nov 12 23:09 ca.key</code></pre><p>创建证书过程中需要输入所在地、公司名称，因为本文生成证书的目的只是开发测试，所以这里是随便填写的。执行完成后能够看到一份<code>ca.crt</code>文件。</p><h2 id="签发身份证书"><a href="#签发身份证书" class="headerlink" title="签发身份证书"></a><span id="签发身份证书">签发身份证书</span></h2><p>跳转到 cert 目录下。</p><h3 id="生成私钥"><a href="#生成私钥" class="headerlink" title="生成私钥"></a>生成私钥</h3><p>操作和刚才生成CA私钥一样，不再赘述。</p><pre><code class="shell">workdir/cert# openssl genrsa -aes128 -out server.key 4096Generating RSA private key, 4096 bit long modulus.............................++........................................................................................................................................................................................................................++e is 65537 (0x010001)Enter pass phrase for server.key:Verifying - Enter pass phrase for server.key:workdir/cert# lltotal 12drwxr-xr-x 2 root root 4096 Nov 12 23:32 ./drwxr-xr-x 4 root root 4096 Nov 12 23:31 ../-rw------- 1 root root 3326 Nov 12 23:32 server.key</code></pre><h3 id="创建证书请求文件"><a href="#创建证书请求文件" class="headerlink" title="创建证书请求文件"></a>创建证书请求文件</h3><p>创建证书请求文件需要用到上一步创建的私钥文件（<code>server.key</code>)。<code>A challenge password</code>和<code>An optional company name</code>那里可以直接敲回车跳过不填。</p><pre><code class="shell">workdir/cert# openssl req -new -key server.key -out server.csrEnter pass phrase for server.key:You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#39;.&#39;, the field will be left blank.-----Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:GuangdongLocality Name (eg, city) []:ShenzhenOrganization Name (eg, company) [Internet Widgits Pty Ltd]:xxxOrganizational Unit Name (eg, section) []:xxxCommon Name (e.g. server FQDN or YOUR name) []:xxxEmail Address []:xxx@xxx.xxxPlease enter the following &#39;extra&#39; attributesto be sent with your certificate requestA challenge password []:An optional company name []:workdir/cert# lltotal 16drwxr-xr-x 2 root root 4096 Nov 12 23:42 ./drwxr-xr-x 4 root root 4096 Nov 12 23:31 ../-rw-r--r-- 1 root root 1724 Nov 12 23:42 server.csr-rw------- 1 root root 3326 Nov 12 23:32 server.key</code></pre><p>执行完成后目录下会出现一份<code>server.csr</code>文件。</p><h3 id="签发证书文件"><a href="#签发证书文件" class="headerlink" title="签发证书文件"></a>签发证书文件</h3><p>注意这里执行的命令会指定使用上面创建的CA证书以及CA私钥文件（<code>-CA ../ca/ca.crt -CAkey ../ca/ca.key</code>），有效期为3650天，输出文件为<code>server.crt</code>。</p><pre><code class="shell">workdir/cert# openssl x509 -req -days 3650 -in server.csr -CA ../ca/ca.crt -CAkey ../ca/ca.key -CAcreateserial -out server.crtSignature oksubject=C = CN, ST = Guangdong, L = Shenzhen, O = xxx, OU = xxx, CN = xxx, emailAddress = xxx@xxx.xxxGetting CA Private KeyEnter pass phrase for ../ca/ca.key:workdir/cert# lltotal 24drwxr-xr-x 2 root root 4096 Nov 12 23:49 ./drwxr-xr-x 4 root root 4096 Nov 12 23:31 ../-rw-r--r-- 1 root root 1948 Nov 12 23:49 server.crt-rw-r--r-- 1 root root 1724 Nov 12 23:42 server.csr-rw------- 1 root root 3326 Nov 12 23:32 server.key-rw-r--r-- 1 root root   17 Nov 12 23:49 .srl</code></pre><h3 id="将crt证书转换为PKCS12格式"><a href="#将crt证书转换为PKCS12格式" class="headerlink" title="将crt证书转换为PKCS12格式"></a>将crt证书转换为PKCS12格式</h3><p>上一步其实已经成功创建出身份证书了（就是<code>server.crt</code>），这里把该文件转换成PKCS12格式，方便Java服务使用。<br><strong>注意</strong>：这一步需要输入私钥<code>server.key</code>的密码，导出证书的密码可由读者自行设置。</p><pre><code class="shell">workdir/cert# openssl pkcs12 -export -in server.crt -inkey server.key -out server.p12Enter pass phrase for server.key:Enter Export Password:Verifying - Enter Export Password:workdir/cert# lltotal 32drwxr-xr-x 2 root root 4096 Nov 13 00:09 ./drwxr-xr-x 5 root root 4096 Nov 12 23:52 ../-rw-r--r-- 1 root root 1948 Nov 12 23:49 server.crt-rw-r--r-- 1 root root 1724 Nov 12 23:42 server.csr-rw------- 1 root root 3326 Nov 12 23:32 server.key-rw------- 1 root root 4157 Nov 13 00:09 server.p12-rw-r--r-- 1 root root   17 Nov 12 23:49 .srl</code></pre><h2 id="创建信任证书"><a href="#创建信任证书" class="headerlink" title="创建信任证书"></a>创建信任证书</h2><p>跳转到trust目录。</p><h3 id="创建keystore文件"><a href="#创建keystore文件" class="headerlink" title="创建keystore文件"></a>创建keystore文件</h3><p>使用keytool新建一份 keystore 文件，这个文件会被用作信任证书：</p><pre><code class="shell">workdir/trust# keytool -genkeypair -alias trust -keystore trust.jks -keyalg RSA -sigalg SHA1withRSAEnter keystore password:Re-enter new password:What is your first and last name?  [Unknown]:  xxxWhat is the name of your organizational unit?  [Unknown]:  xxxWhat is the name of your organization?  [Unknown]:  xxxWhat is the name of your City or Locality?  [Unknown]:  ShenzhenWhat is the name of your State or Province?  [Unknown]:  GuangdongWhat is the two-letter country code for this unit?  [Unknown]:  CNIs CN=xxx, OU=xxx, O=xxx, L=Shenzhen, ST=Guangdong, C=CN correct?  [no]:  yes</code></pre><p><strong>注意</strong>：创建过程中<code>keytool</code>会要求你给这份 keystore 文件设置密码。<br>执行成功的话会在trust目录下生成一份 keystore 文件：</p><pre><code>workdir/trust# lltotal 12drwxr-xr-x 2 root root 4096 Nov 12 23:54 ./drwxr-xr-x 5 root root 4096 Nov 12 23:52 ../-rw-r--r-- 1 root root 2557 Nov 12 23:54 trust.jks</code></pre><h3 id="导入CA证书"><a href="#导入CA证书" class="headerlink" title="导入CA证书"></a>导入CA证书</h3><p>将前文创建的CA证书导入到<code>trust.jks</code>文件中，这样，使用此CA证书签发的TLS证书就都被这份 keystore 文件信任了。<br><strong>注意</strong>：导入过程需要输入<code>trust.jks</code>文件的密码，也可以在命令中使用<code>-storepass</code>参数输入密码。</p><pre><code class="shell">workdir/trust# keytool -import -file ../ca/ca.crt -keystore trust.jksEnter keystore password:Owner: EMAILADDRESS=xxx@xxx.xxx, CN=xxx, OU=xxx, O=xxx, L=Shenzhen, ST=Guangdong, C=CNIssuer: EMAILADDRESS=xxx@xxx.xxx, CN=xxx, OU=xxx, O=xxx, L=Shenzhen, ST=Guangdong, C=CNSerial number: d66ebd9ea172d18aValid from: Tue Nov 12 23:21:27 CST 2019 until: Fri Nov 09 23:21:27 CST 2029Certificate fingerprints:         SHA1: A2:19:67:E6:D2:A2:6E:7E:E6:C8:15:2C:CD:F7:48:70:EF:85:03:8D         SHA256: 58:FF:94:50:E4:22:73:A3:8C:77:7D:6E:06:38:D6:98:0D:0D:58:83:44:46:93:CB:4E:56:48:AE:AC:41:63:F0Signature algorithm name: SHA256withRSASubject Public Key Algorithm: 4096-bit RSA keyVersion: 3Extensions:#1: ObjectId: 2.5.29.35 Criticality=falseAuthorityKeyIdentifier [KeyIdentifier [0000: 95 4E 27 2B 65 7C E6 8F   E3 F8 46 7D 09 3B 44 ED  .N&#39;+e.....F..;D.0010: 08 60 94 00                                        .`..]]#2: ObjectId: 2.5.29.19 Criticality=trueBasicConstraints:[  CA:true  PathLen:2147483647]#3: ObjectId: 2.5.29.14 Criticality=falseSubjectKeyIdentifier [KeyIdentifier [0000: 95 4E 27 2B 65 7C E6 8F   E3 F8 46 7D 09 3B 44 ED  .N&#39;+e.....F..;D.0010: 08 60 94 00                                        .`..]]Trust this certificate? [no]:  yesCertificate was added to keystore</code></pre><p>执行成功后，可以运行<code>keytool -list -v -keystore trust.jks</code>命令查看导入的内容。</p><h2 id="完成"><a href="#完成" class="headerlink" title="完成"></a>完成</h2><p>至此，证书生成工作就完成了。对于Java服务，可以使用<code>cert</code>目录下的<code>server.p12</code>作为身份证书，<code>trust</code>目录下的<code>trust.jks</code>作为信任证书来启动服务。<br><code>trust.jks</code>信任了签发<code>server.p12</code>的CA证书，所以客户端、服务端程序开启TLS对端认证进行测试时，可以使用同一套证书，<br>也可以重复<a href="#签发身份证书">签发身份证书</a>的步骤签发多套证书。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="如何查看证书"><a href="#如何查看证书" class="headerlink" title="如何查看证书"></a>如何查看证书</h3><ul><li><p>使用keytool查看crt证书：</p><p><code>keytool -printcert -v -file server.crt</code></p></li><li><p>使用keytool查看keystore文件：</p><p><code>keytool -list -v -keystore trust.jks</code></p></li><li><p>使用OpenSSL查看crt证书：</p><p><code>openssl x509 -in server.crt -text -noout</code></p></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://www.cnblogs.com/yjmyzz/p/openssl-tutorial.html" target="_blank" rel="noopener">https://www.cnblogs.com/yjmyzz/p/openssl-tutorial.html</a></li><li><a href="https://sites.google.com/site/ddmwsst/create-your-own-certificate-and-ca" target="_blank" rel="noopener">https://sites.google.com/site/ddmwsst/create-your-own-certificate-and-ca</a></li><li><a href="https://blog.csdn.net/defonds/article/details/85098684" target="_blank" rel="noopener">https://blog.csdn.net/defonds/article/details/85098684</a></li><li><a href="https://blog.csdn.net/linvo/article/details/9150607" target="_blank" rel="noopener">https://blog.csdn.net/linvo/article/details/9150607</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TLS</tag>
      
      <tag>OpenSSL</tag>
      
      <tag>keytool</tag>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>详解Java-Chassis契约校验失败导致的微服务实例注册失败问题</title>
    <link href="undefined2019/03/22/WhySchemaInconsistencyCauseServiceInstanceStartUpFailure/"/>
    <url>2019/03/22/WhySchemaInconsistencyCauseServiceInstanceStartUpFailure/</url>
    
    <content type="html"><![CDATA[<p>一篇文章说清楚为什么ServiceComb-Java-Chassis校验服务契约的机制那么严格。</p><a id="more"></a><h1 id="详解Java-Chassis契约校验失败导致的微服务实例注册失败问题"><a href="#详解Java-Chassis契约校验失败导致的微服务实例注册失败问题" class="headerlink" title="详解Java-Chassis契约校验失败导致的微服务实例注册失败问题"></a>详解Java-Chassis契约校验失败导致的微服务实例注册失败问题</h1><p>相信不少同学在使用 CSEJavaSDK / ServiceComb-Java-Chassis 开发微服务的过程中都碰到过修改了服务接口后服务就无法启动的情况。控制台上会打出如下的异常栈：</p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: ServiceComb init failed.    at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:220)    at org.apache.servicecomb.core.CseApplicationListener.onApplicationEvent(CseApplicationListener.java:81)    at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172)    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165)    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393)    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347)    at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883)    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:93)    at org.apache.servicecomb.foundation.common.utils.BeanUtils.init(BeanUtils.java:49)    at org.apache.servicecomb.foundation.common.utils.BeanUtils.init(BeanUtils.java:42)    at microservice.demo.training21days.provider.AppMain.main(AppMain.java:9)Caused by: java.lang.IllegalStateException: The schema(id=[hello]) content held by this instance and the service center is different. You need to increment microservice version before deploying. Or you can configure service_description.environment=development to work in development environment and ignore this error    at org.apache.servicecomb.serviceregistry.task.MicroserviceRegisterTask.compareAndReRegisterSchema(MicroserviceRegisterTask.java:277)    at org.apache.servicecomb.serviceregistry.task.MicroserviceRegisterTask.registerSchema(MicroserviceRegisterTask.java:206)    at org.apache.servicecomb.serviceregistry.task.MicroserviceRegisterTask.registerSchemas(MicroserviceRegisterTask.java:170)    at org.apache.servicecomb.serviceregistry.task.MicroserviceRegisterTask.doRegister(MicroserviceRegisterTask.java:122)    at org.apache.servicecomb.serviceregistry.task.AbstractRegisterTask.doRun(AbstractRegisterTask.java:41)    at org.apache.servicecomb.serviceregistry.task.AbstractTask.run(AbstractTask.java:53)    at org.apache.servicecomb.serviceregistry.task.CompositeTask.run(CompositeTask.java:35)    at org.apache.servicecomb.serviceregistry.task.ServiceCenterTask.init(ServiceCenterTask.java:82)    at org.apache.servicecomb.serviceregistry.registry.AbstractServiceRegistry.run(AbstractServiceRegistry.java:178)    at org.apache.servicecomb.serviceregistry.registry.RemoteServiceRegistry.run(RemoteServiceRegistry.java:86)    at org.apache.servicecomb.serviceregistry.RegistryUtils.run(RegistryUtils.java:70)    at org.apache.servicecomb.core.SCBEngine.doInit(SCBEngine.java:255)    at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:209)    ... 13 more</code></pre><p>其实这里抛出的异常已经告诉大家问题的原因和解决方式了。问题原因是这个服务在服务中心里注册的契约内容和这个实例实际持有的契约内容不一致（契约的id也打出来了，这里是<code>&quot;hello&quot;</code>）。至于解决方案，这里给出了两种：</p><ol><li>增加微服务的版本，也就是要修改<code>microservice.yaml</code>配置文件里的<code>service_description.version</code>配置项的值</li><li>将环境更改为开发环境，也就是在<code>microservice.yaml</code>配置文件里加上一个配置 <code>service_description.environment=development</code></li></ol><p>那么这里的两种问题解决方式应该选择哪一种呢，还有其他的解决方式吗？我们还是得先从服务契约本身说起。</p><p>一个 ServiceComb-Java-Chassis 框架的微服务在启动时会扫描它全部的REST接口类，并根据这些接口类生成对应的服务契约，并确保它们随着自己的服务记录一起注册到了服务中心。服务契约不仅仅是一份“接口文档”，同时它也约束着微服务的运行时行为。微服务会根据服务契约来确定如何调用其他服务，以及如何执行参数的序列化、反序列化操作等等。<br>也就是说， ServiceComb-Java-Chassis 的服务契约，不是那种大家开发完新功能后想起来要更新了就去改一下，忘记了或者没时间就不改的“接口说明文档”。它跟服务的接口有着严格的对应关系。<strong>如果契约不一样的话，那么就说明，你的服务，真的，有接口变化</strong>。</p><p>说到接口变化，大家都知道这是一个比较严肃的事情了。通常一个服务的接口都应该是经过设计和评审的，不能轻易改变（跟其他服务联调过的同学对这个应该有体会吧？）。<br>在正式的环境（生产环境）下，服务接口变更发生在什么时候呢？答案是，服务版本变更的时候。抛开那些不按套路出牌的开发团队不谈，一般情况下一个服务版本应该上线哪些功能，提供哪些接口，都是应该有规划和记录的。也就是说，一个服务的每个版本的接口都是确定的，不应该出现一个版本的服务有两套不同的接口的情况。</p><p>到这里，大家知道为什么你会碰到本文开头碰到的问题了吧？<br>原因很明确，就是<strong>你不应该在一个版本的微服务里给出两套不相同的接口</strong>。想想如果你的生产环境里，同一个版本的微服务混进去了一批接口不一样的服务实例（微服务架构下通常都是多实例部署服务的），那么你的系统一会儿可以正常工作，一会儿报各种参数错误、接口不存在之类的问题。这些问题的表象可能会显得很隐晦、随机或者复杂，而你在线上环境里很难排查出来。<br>为了避免将这类问题引入到线上， CSEJavaSDK / ServiceComb-Java-Chassis 采取了严格的服务契约校验策略，确保你的线上的服务一定是接口一致的。</p><p>所以异常里给出的两种解决方案其实也是针对不同的场景的：</p><ol><li>如果你正在开发新版本的服务，接口本来就变来变去的没定下来，那么你可以把你的微服务的环境改为开发环境（<code>service_description.environment=development</code>），此时微服务框架允许你变更你的接口并更新注册到服务中心。</li><li>如果是测试、生产环境，这个时候服务接口应该稳定下来了，服务契约不同通常意味着这应该是一个新版本。那么你应该给你的服务分配一个更新的版本号了。</li></ol><p>顺带一提，开发自测时还有一种问题解决办法，就是直接把服务中心里的旧服务记录删掉，更简单 ; )</p><blockquote><p>删完记得把上游调用它的服务重启一下，consumer端只加载一次provider的服务契约，之后不再动态刷新的</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>microservice</tag>
      
      <tag>ServiceComb-Java-Chassis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录一个Spring ApplicationContext重复加载的问题</title>
    <link href="undefined2018/12/29/TomcatContextDuplicateLoadingProblem/"/>
    <url>2018/12/29/TomcatContextDuplicateLoadingProblem/</url>
    
    <content type="html"><![CDATA[<p>Spring ApplicationContext重复加载可能造成各种奇怪问题，如无法自动注入Spring Bean、Spring Bean重复加载报错等等。仔细观察启动日志通常能从Spring应用上下文加载日志中看出一点端倪。</p><a id="more"></a><h1 id="记录一个Spring-ApplicationContext重复加载的问题"><a href="#记录一个Spring-ApplicationContext重复加载的问题" class="headerlink" title="记录一个Spring ApplicationContext重复加载的问题"></a>记录一个Spring ApplicationContext重复加载的问题</h1><h2 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h2><p>有同事开发了一个demo服务，服务包含前端页面和ServiceComb开发的REST后端服务两部分。打成war包部署在Tomcat中，发现这个服务会在服务中心注册两个地址相同的实例。观察日志，发现Spring Context加载了两遍，并且Tomcat的webapps目录下存在一个与war包同名的目录和一个ROOT目录，两个目录中的内容是相同的。</p><h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>Tomcat在启动时会将webapps目录下的war包解压到一个同名目录下，将其作为一个context加载。而在Tomcat的<code>conf/server.xml</code>文件中，又额外定义了一个Context：</p><pre><code class="xml">&lt;Context path=&quot;/&quot; reloadable=&quot;true&quot; docBase=&quot;${war包的名字}&quot;/&gt;</code></pre><p>于是该war包会作为root context 又被加载一次。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>删掉<code>conf/server.xml</code>文件中定义的context，把拷贝到webapps目录下的war包改名为<code>ROOT.war</code>。Tomcat启动时会自动将war包解压作为root context加载。</p>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
      <category>踩坑</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker容器内部署Java微服务的内存限制问题</title>
    <link href="undefined2018/11/24/MemoryConsumingOfJvmInDocker/"/>
    <url>2018/11/24/MemoryConsumingOfJvmInDocker/</url>
    
    <content type="html"><![CDATA[<p>警惕JVM占用内存超过K8S容器内存配额限制，进而导致微服务进程被关闭的问题。</p><a id="more"></a><h1 id="Docker容器内部署Java微服务的内存限制问题"><a href="#Docker容器内部署Java微服务的内存限制问题" class="headerlink" title="Docker容器内部署Java微服务的内存限制问题"></a>Docker容器内部署Java微服务的内存限制问题</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前两天有同事发现，通过华为云 ServiceStage 的流水线部署基于模板创建的 CSEJavaSDK demo 服务时，会在容器启动过程中报错。初步排查是由于 JVM 占用的内存超出了 docker 内存配额的上限，导致容器被 kill 掉。于是我们需要排查一下问题出在哪里，为什么以前没有这类问题，而现在却发生了。</p><h2 id="基本定位"><a href="#基本定位" class="headerlink" title="基本定位"></a>基本定位</h2><p>要确定 docker 容器内存超限问题的直接原因并不难。直接进入docker容器，执行 <code>top</code> 命令，我们发现宿主机是一台8核16G的机器，而且 docker 并不会屏蔽这些信息，也就是 JVM 会认为自己工作于一台 16G 内存的机器上。而查看 demo 服务的 Dockerfile，发现运行服务时并没有对 JVM 的内存进行任何限制，于是 JVM 会根据默认的设置来工作 —— 最大堆内存为物理内存的1/4(这里的描述并不完全准确，因为 JVM 的默认堆内存大小限制比例其实是根据物理内存有所变化的，具体内容请自行搜索资料)，而基于模板创建的 ServiceStage 流水线，在部署应用堆栈的时候会把 docker 容器的内存配额默认设置为 512M，于是容器就会在启动的时候内存超限了。至于以前没有碰到过这种问题的原因，只是因为以前没将这么高规格的 ECS 服务器用于流水线部署应用堆栈。</p><p>在查询过相关资料后，我们找到了两种问题解决方案，一个是直接在 jar 包运行命令里加上 <code>-Xmx</code> 参数来指定最大堆内存，不过这种方式只能将 JVM 堆内存限制为一个固定的值；另一个方法是在执行 jar 包时加上 <code>-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap</code> 参数，让 JVM 能够感知到docker容器所设置的 <code>cgroup</code> 限制，相应地调整自身的堆内存大小，不过这个特性是 JDK 8u131 以上的版本才具备的。</p><p>最终，我们提醒 ServiceStage 流水线的同学将 CSEJavaSDK demo 的创建模板做了改进，在 Dockerfile 中将打包的基础镜像版本由原先的 <code>java:8u111-jre-alpine</code> 升级为了 <code>openjdk:8u181-jdk-alpine</code>，并且在运行服务 jar 包的命令中加上了 <code>-Xmx256m</code> 参数。问题至此已经解决了。</p><h2 id="进一步的探究"><a href="#进一步的探究" class="headerlink" title="进一步的探究"></a>进一步的探究</h2><p>虽然问题已经解决，但是在好奇心的驱使下，我还是打算自己找个 demo 实际去触发一下问题，另外看看从网上搜到的解决方法到底好不好用 : )</p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ol><li><p>创建云上工程</p><p><img src="/img/blog/MemoryConsumingOfJvmInDocker/create_cloud-base_project.PNG" srcset="/img/loading.gif" alt=""></p><p>首先需要在华为云 ServiceStage 创建一个云上工程。</p><p>在 ServiceStage -&gt; 应用开发 -&gt; 微服务开发 -&gt; 工程管理 -&gt; 创建云上工程中，选择“基于模板创建”，语言选择 Java， 框架选择 <code>CSE-Java (SpringMVC)</code>，部署系统选择“云容器引擎CCE”，给你的云上工程取一个名字，比如<code>test-memo-consuming</code>，最后选择存放代码的仓库，就可以完成云上工程的创建了。</p><p>之后云上工程会根据你的选项自动地生成脚手架代码，上传到你指定的代码仓库中，并且为你创建一条流水线，完成代码编译、构建、打包、归档镜像包的操作，并且使用打好的 docker 镜像包在 CCE 集群中部署一个应用堆栈。</p><blockquote><p>创建云上工程和流水线不是本文的重点，我就不详细讲操作了 : )。同一个应用堆栈的实例可以部署多个，在这里为了实验方便就按照默认值1个来部署。</p></blockquote><p><img src="/img/blog/MemoryConsumingOfJvmInDocker/demo_service_instance.PNG" srcset="/img/loading.gif" alt=""><br>由于云上工程已经改进了脚手架代码的模板，不会再出现内存超限的问题，所以我们现在能看到 demo 服务已经正常的跑起来，微服务实例已经注册到服务中心了。</p><p><img src="/img/blog/MemoryConsumingOfJvmInDocker/curl_helloworld.PNG" srcset="/img/loading.gif" alt=""><br>登录到 demo 服务所部署的容器，使用<code>curl</code>命令可以调用 demo 服务的 helloworld 接口，可以看到此时服务已经可以正常工作。</p></li><li><p>增加实验代码</p><p>为了能够触发微服务实例消耗更多的内存，我在项目代码中增加了如下接口，当调用<code>/allocateMemory</code>接口时，微服务实例会不停申请内存，直到 JVM 抛出 OOM 错误或者容器内存超限被 kill 掉。</p><pre><code class="java">private HashMap&lt;String, long[]&gt; cacheMap = new HashMap&lt;&gt;();@GetMapping(value = &quot;/allocateMemory&quot;)public String allocateMemory() { LOGGER.info(&quot;allocateMemory() is called&quot;); try {   for (long i = 0; true; ++i) {     cacheMap.put(&quot;key&quot; + i, new long[1024 * 1024]);   } } catch (Throwable t) {   LOGGER.info(&quot;allocateMemory() gets error&quot;, t); } return &quot;allocated&quot;;}</code></pre><p>此时用来打镜像包的基础镜像是<code>openjdk:8u181-jdk-alpine</code>，jar 包启动命令中加上了<code>-Xmx256m</code>参数。</p><p>执行流水线，应用堆栈部署成功后，调用<code>/allocateMemory</code>接口触发微服务实例消耗内存，直到 JVM 抛出 OOM 错误，可以在 ServiceStage -&gt; 应用上线 -&gt; 应用管理中选择相应的应用，点击进入概览页面，查看应用使用内存的情况。</p><p><img src="/img/blog/MemoryConsumingOfJvmInDocker/deploy_normal.PNG" srcset="/img/loading.gif" alt=""><br>应用使用的内存从 800M+ 陡然下降的时间点就是我重新打包部署的时间，而之后由于调用<code>/allocateMemory</code>接口，内存占用量上升到了接近 400M，并且在这个水平稳定了下来，显示<code>-Xmx256m</code>参数发挥了预期的作用。</p></li></ol><h3 id="复现问题"><a href="#复现问题" class="headerlink" title="复现问题"></a>复现问题</h3><p>现在将 demo 工程中的 Dockerfile 修改一下，将基础镜像改为 <code>java:8u111-jre-alpine</code>，并且删除启动命令中的<code>-Xmx256m</code>参数，将其提交为<code>noLimit_oldBase</code>分支，推送到代码仓库中。然后编辑流水线，将 source 阶段的任务所使用的代码分支改为<code>noLimit_oldBase</code>分支，保存并重新运行流水线，将新的代码打包部署到应用堆栈中。</p><div align=center><img src="/img/blog/MemoryConsumingOfJvmInDocker/deploy_noLimit_oldBase.PNG" srcset="/img/loading.gif" width="50%" height="50%"/></div>在微服务实例列表中查询到新的微服务实例的 endpoint IP 后，调用`/allocateMemory`接口，观察内存情况，内存从接近 400M 突然掉下去一下，然后又上升到约 450M 的时间点就是修改代码后的微服务实例部署成功的时间点，之后内存占用量突然下跌就是因为调用`/allocateMemory`接口导致容器内存超限被 kill 掉了。<p>如果你事先使用<code>docker logs -f</code>命令查看容器日志的话，那么日志大概是这个样子的</p><pre><code>2018-11-23 15:40:04,920  INFO SCBEngine:152 - receive MicroserviceInstanceRegisterTask event, check instance Id...2018-11-23 15:40:04,920  INFO SCBEngine:154 - instance registry succeeds for the first time, will send AFTER_REGISTRY event.2018-11-23 15:40:04,925  WARN VertxTLSBuilder:116 - keyStore [server.p12] file not exist, please check!2018-11-23 15:40:04,925  WARN VertxTLSBuilder:136 - trustStore [trust.jks] file not exist, please check!2018-11-23 15:40:04,928  INFO DataFactory:62 - Monitor data sender started. Configured data providers is {com.huawei.paas.cse.tcc.upload.TransactionMonitorDataProvider,com.huawei.paas.monitor.HealthMonitorDataProvider,}2018-11-23 15:40:04,929  INFO ServiceCenterTask:51 - read MicroserviceInstanceRegisterTask status is FINISHED2018-11-23 15:40:04,939  INFO TestmemoconsumingApplication:57 - Started TestmemoconsumingApplication in 34.81 seconds (JVM running for 38.752)2018-11-23 15:40:14,943  INFO AbstractServiceRegistry:258 - find instances[1] from service center success. service=default/CseMonitoring/latest, old revision=null, new revision=28475010.12018-11-23 15:40:14,943  INFO AbstractServiceRegistry:266 - service id=8b09a7085f4011e89f130255ac10470c, instance id=8b160d485f4011e89f130255ac10470c, endpoints=[rest://100.125.0.198:30109?sslEnabled=true]2018-11-23 15:40:34,937  INFO ServiceCenterTaskMonitor:39 - sc task interval changed from -1 to 302018-11-23 15:47:03,823  INFO SPIServiceUtils:76 - Found SPI service javax.ws.rs.core.Response$StatusType, count=0.2018-11-23 15:47:04,657  INFO TestmemoconsumingImpl:39 - allocateMemory() is calledKilled</code></pre><p>可以看到<code>allocateMemory</code>方法被调用，然后 JVM 还没来得及抛出 OOM 错误，整个容器就被 kill 掉了。</p><blockquote><p>这里也给大家提了一个醒：<strong>不要以为自己的服务容器能启动起来就万事大吉了</strong>，如果没有特定的限制，JVM 会在运行时继续申请堆内存，也有可能造成内存用量超过 docker 容器的配额！</p></blockquote><h3 id="让-JVM-感知cgroup限制"><a href="#让-JVM-感知cgroup限制" class="headerlink" title="让 JVM 感知cgroup限制"></a>让 JVM 感知<code>cgroup</code>限制</h3><p>前文提到还有另外一种方法解决 JVM 内存超限的问题，这种方法可以让 JVM 自动感知 docker 容器的 <code>cgroup</code> 限制，从而动态的调整堆内存大小，感觉挺不错的。我们也来试一下这种方法，看看效果如何 ; )</p><p>回到demo项目代码的<code>master</code>分支，将 Dockerfile 中启动命令参数的<code>-Xmx256m</code>替换为<code>-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap</code>，提交为<code>useCGroupMemoryLimitForHeap</code>分支，推送到代码仓库里。再次运行流水线进行构建部署。</p><div align=center><img src="/img/blog/MemoryConsumingOfJvmInDocker/deploy_useCGroupMemoryLimitForHeap.PNG" srcset="/img/loading.gif" width="50%" height="50%"/></div>等 demo 服务部署成功后，再次调用`/allocateMemory`接口，容器的内存占用情况如上图所示（最右边的那一部分连续曲线），内存上升到一定程度后，JVM 抛出了 OOM 错误，没有继续申请堆内存。看来这种方式也是有效果的。<p>不过，仔细观察容器的内存占用情况，可以发现容器所使用的内存仅为不到 300M，而我们对于这个容器的内存配额限制为 512M，也就是还有 200M+ 是闲置的，并不会被 JVM 利用。这个利用率，比起上文中直接设置<code>-Xmx256m</code>的内存利用率要低 : ( 。推测是因为 JVM 并不会感知到自己是部署在一个 docker 容器里的，所以它把当前的环境当成一个物理内存只有 512M 的物理机，按照比例来限制自己的最大堆内存，另一部分就被闲置了。</p><blockquote><p>如此看来，如果想要充分利用自己的服务器资源，还是得多花一点功夫，手动调整好<code>-Xmx</code>参数。</p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://royvanrijn.com/blog/2018/05/java-and-docker-memory-limits/" target="_blank" rel="noopener" title="Java and Docker, the limitations">Java and Docker, the limitations</a></li><li><a href="https://developers.redhat.com/blog/2017/03/14/java-inside-docker/" target="_blank" rel="noopener" title="Java inside docker: What you must know to not FAIL - RHD Blog">Java inside docker: What you must know to not FAIL</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
      <category>踩坑</category>
      
    </categories>
    
    
    <tags>
      
      <tag>microservice</tag>
      
      <tag>ServiceComb-Java-Chassis</tag>
      
      <tag>K8S</tag>
      
      <tag>docker</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源项目没有那么遥远</title>
    <link href="undefined2018/11/18/BecomingApacheServiceCombCommiter/"/>
    <url>2018/11/18/BecomingApacheServiceCombCommiter/</url>
    
    <content type="html"><![CDATA[<p>从小白到Apache项目Committer的成长之路。</p><a id="more"></a><h1 id="开源项目没有那么遥远"><a href="#开源项目没有那么遥远" class="headerlink" title="开源项目没有那么遥远"></a>开源项目没有那么遥远</h1><blockquote><p>前几天收到了Apache ServiceComb PMC的邀请邮件，这意味着我成为了一名Apache ServiceComb项目的Committer。喜悦之余，我想留下一篇博客作为自己工作的一个阶段性总结，同时也希望这篇文章能够给其他想要加入到开源社区的同学一点参考。</p></blockquote><h2 id="初次接触ServiceComb"><a href="#初次接触ServiceComb" class="headerlink" title="初次接触ServiceComb"></a>初次接触ServiceComb</h2><p>最开始接触到“开源”的概念是在大学的计算机课程上，当时对于开源项目的印象就是：开源项目是由一群大牛程序员开发和维护的，作为小白的我只需要拿来用就好了。</p><p>毕业之后参加工作，我被分到了一个跟开源项目相关的工作组，需要向<a href="https://servicecomb.apache.org/cn/" target="_blank" rel="noopener" title="ServiceComb官网">Apache ServiceComb项目</a>提交代码。当时的心情真是既新奇又紧张，毕竟以前只是单纯地使用过开源软件，而现在自己终于要向开源软件项目提交代码了。这种能够在一个开源项目中提交自己代码的兴奋感，相信很多学软件专业的同学应该能够理解。但是自己又是刚开始工作的小白，担心自己写的代码太差了拿不出手，因此又紧张不已。而事实上我第一次提交代码的经过并没有预想中的那么多波折，作为一个开源小白，提上去的pull request有瑕疵是很正常的事情，根据检视者的意见修改好了就行——毕竟高手不一定高冷，社区的开发者们都是很热心的。</p><p>有了第一次提交PR的经历后，后面的工作就慢慢变得轻车熟路了。平常我在开源社区主要做的就是领一些新特性或者修复bug的<a href="https://issues.apache.org/jira/projects/SCB/issues" target="_blank" rel="noopener" title="Apache issues">issue</a>处理，提交代码或文档的修改。</p><h2 id="参与的方式不仅仅是写代码……"><a href="#参与的方式不仅仅是写代码……" class="headerlink" title="参与的方式不仅仅是写代码……"></a>参与的方式不仅仅是写代码……</h2><p>如前文所提到的，最初我参与Apache ServiceComb开源项目的内容是由工作驱动的。因为有一些新特性要完成，或者因为有一些bug要修复，所以我需要提交代码和更新相关文档。而在代码和文档之外的其他事务我并没有参与多少。</p><p>其实从我开始向ServiceComb提交代码时，我就订阅了<a href="https://servicecomb.apache.org/cn/developers/subscribe-mail-list/" target="_blank" rel="noopener" title="订阅邮件">Apache ServiceComb的邮件列表</a>，也加入了<a href="https://servicecomb.apache.org/cn/developers/use-gitter/" target="_blank" rel="noopener" title="使用Gitter">Gitter聊天室</a>。不过由于对自己的技术没什么自信，也受限于内向的性格，我在这些沟通渠道内长期保持着旁观的状态。当时的想法是，讨论ServiceComb设计和发展的事情我又参与不了，看看大佬们讨论就可以，到时候我再捞几个issue来做就好了。然而这种想法是不对的，对于我们自身在开源社区中的发展也没有好处。要参与开源社区的事务，仅仅只是埋头提交代码是不够的，积极参与社区的讨论、沟通，保持自己在社区中的活跃度，也是评判自己在社区工作好坏的一项标准。这也符合Apache之道中“社区胜于代码”的理念。此外，把将要进行的事情放到邮件中讨论，也是一个文档归档的过程。后续想要回溯某个特性为什么会被加进来，或者某个bug是如何触发的时候，搜索相关的邮件就可以了。如果有新的贡献者想要参与到社区开发工作中来，他们也可以通过查阅邮件来了解很多信息。这在无形中节省了很多后续的维护和沟通成本。</p><p>参与社区讨论的活跃程度也是评判一个开发者能否成为committer的重要标准。听先前已经进入ServiceComb社区的同事说，其实按照我的代码提交量来看，在之前我就可以成为committer了，然而由于我在社区沟通中的活跃度实在是太低了，所以才一直没有受到ServiceComb PMC的committer邀请……所以说，同学们一定不要被自己的腼腆性格坑了啊，要参与社区事务，就需要更积极地加入到讨论中来。</p><h2 id="给有意者的一些建议"><a href="#给有意者的一些建议" class="headerlink" title="给有意者的一些建议"></a>给有意者的一些建议</h2><p>参与一个开源项目，对于自己阅读文档、分析源码、开发和沟通的能力都有很大的益处。这和开发一个业务系统是两种完全不同的体验，对于拓展个人的视野和经验很有帮助，我想大家应该从各种文章里了解很多了，我在这里就不多讲了 : )</p><p>如果想要参与到一个开源项目中，可以首先了解一下如何使用这个项目。给开源社区做贡献的方式不仅仅限于提交代码，<a href="https://github.com/apache/servicecomb-docs" target="_blank" rel="noopener" title="ServiceComb文档项目">修复文档问题</a>可能是一个更好的切入点。通过阅读和修复文档问题，我们可以了解到一个项目的主要特性，这对于我们进一步了解项目源码也是很有帮助的。</p><p>同时，<a href="https://servicecomb.apache.org/cn/developers/subscribe-mail-list/" target="_blank" rel="noopener" title="订阅邮件">订阅邮件列表</a>和<a href="https://servicecomb.apache.org/cn/developers/use-gitter/" target="_blank" rel="noopener" title="使用Gitter">使用Gitter</a>也很有必要。通过这些，我们不仅可以了解到项目的最新动态，也能够参与到社区的讨论中来。如果还不了解如何发起一场讨论的话，可以先看看社区里的开发者是怎么做的，参与到其他人的邮件讨论中去。碰到其他的使用者提问也可以上去帮助解答，这同样是一种参与贡献的方式。上文已经提到过了，参与讨论沟通是社区活动的重要内容。不用感到不好意思，开源社区本身就是开放的，我们欢迎更多的人能够参与到项目的建设中来。</p><p>正所谓临渊羡鱼，不如退而结网。与其羡慕已经成功参与到开源项目中的同学，不如从现在开始行动，选择一个开源项目参与进去 ; )</p><p>文章的最后，我想向给与我帮助和鼓励的社区团队成员致以感谢，谢谢大家热心的帮助和指导，让我从一名小白成长为Apache committer。</p><blockquote><p>ps：在这里小小地安利一下，<a href="https://servicecomb.apache.org/cn/" target="_blank" rel="noopener" title="ServiceComb官网">Apache ServiceComb项目</a>已经从Apache孵化器毕业，正式成为Apache顶级项目，这也是业界首个微服务项目在Apache孵化并毕业成为顶级项目。ServiceComb中包含的几个子项目都处于如火如荼的发展势头中，欢迎大家参与到ServiceComb社区建设中来~</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>职业发展</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ServiceComb</tag>
      
      <tag>开源</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ServiceComb】微服务调用，应答返回时报ClassCastException问题的定位</title>
    <link href="undefined2018/08/09/DecodeResponseErrorProblemLocation/"/>
    <url>2018/08/09/DecodeResponseErrorProblemLocation/</url>
    
    <content type="html"><![CDATA[<p>记录一个返回值反序列化及类型转换的问题。</p><a id="more"></a><h1 id="【ServiceComb】微服务调用，应答返回时报ClassCastException问题的定位"><a href="#【ServiceComb】微服务调用，应答返回时报ClassCastException问题的定位" class="headerlink" title="【ServiceComb】微服务调用，应答返回时报ClassCastException问题的定位"></a>【ServiceComb】微服务调用，应答返回时报ClassCastException问题的定位</h1><blockquote><p>本文基于CSEJavaSDK-2.3.35版本进行描述，对应的ServiceComb-Java-Chassis版本是1.1.0.B006。<br>文中的示例业务日志和代码来自<a href="https://github.com/yhs0092/CSEBlogDemo-DecodeResponseError" target="_blank" rel="noopener">问题复现demo</a>。</p></blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>问题复现demo在<a href="https://github.com/yhs0092/CSEBlogDemo-DecodeResponseError" target="_blank" rel="noopener">这里</a>。</p><p>前几天被拉去看一个问题。某服务（后面称其为A服务）采用同步模式运行，RPC方式调用其他微服务。在本地调试无问题，线上运行时此服务调用另外一个服务（后面称其为B服务）的接口会报错，且通过他们自定义扩展的一个<code>HttpClientFilter</code>的日志来看，被调用的provider服务已经正常返回了应答消息，但是在后面会报<code>ClassCastException</code>，无法将<code>InvocationException</code>转型为业务代码的返回值类型。日志如下：</p><pre><code>// 业务逻辑被调用[INFO] test() is called! com.github.yhs0092.blogdemo.javachassis.service.ConsumerService.test(ConsumerService.java:20)// 用户自定义的HttpClientFilter中打印了provider返回的消息[INFO] get response, status[200], content is [{&quot;content&quot;:&quot;returnOK&quot;}] com.github.yhs0092.blogdemo.javachassis.filter.PrintResponseFilter.afterReceiveResponse(PrintResponseFilter.java:26)// ClassCastException被抛出[ERROR] invoke failed, invocation=PRODUCER rest client.consumer.test org.apache.servicecomb.swagger.invocation.exception.DefaultExceptionToResponseConverter.convert(DefaultExceptionToResponseConverter.java:35)java.lang.ClassCastException: org.apache.servicecomb.swagger.invocation.exception.InvocationException cannot be cast to com.github.yhs0092.blogdemo.javachassis.service.TestResponse    at com.sun.proxy.$Proxy30.test(Unknown Source)    at com.github.yhs0092.blogdemo.javachassis.service.ConsumerService.test(ConsumerService.java:21)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke(Method.java:498)    at org.apache.servicecomb.swagger.engine.SwaggerProducerOperation.doInvoke(SwaggerProducerOperation.java:160)    at org.apache.servicecomb.swagger.engine.SwaggerProducerOperation.syncInvoke(SwaggerProducerOperation.java:148)    at org.apache.servicecomb.swagger.engine.SwaggerProducerOperation.invoke(SwaggerProducerOperation.java:115)    at org.apache.servicecomb.core.handler.impl.ProducerOperationHandler.handle(ProducerOperationHandler.java:40)</code></pre><p>分析问题的过程中，他们提到由于线上的B服务还是旧版本的没有升级，于是他们把A服务依赖的B服务的接口jar包替换成了低版本来启动的。</p><h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>初步接触这个问题给人一种很怪异的感觉。如果一个consumer调用provider时都已经拿到了应答，那么会直接把应答返回给consumer的业务逻辑代码；万一中间真的出错了，那产生的<code>InvocationException</code>也应该是被“抛”出去的，而不是像日志里面显示的那样，尝试“返回”给consumer的业务逻辑才对。</p><p>可供分析的信息太少了，只能回头看一下sdk代码的相关逻辑，看看能不能复现出这个问题。</p><p>RPC调用模式的微服务里，业务逻辑通过provider接口做调用时，实际是通过ServiceComb生成的provider接口类型的代理来做调用的。而在这个代理的背后，实际调用流程的源头在<code>org.apache.servicecomb.provider.pojo.Invoker</code>类里面。同步调用模式下，区分应答如何被返回给业务逻辑的关键代码在<code>syncInvoke</code>方法里：</p><pre><code class="java">protected Object syncInvoke(Invocation invocation, SwaggerConsumerOperation consumerOperation) {  Response response = InvokerUtils.innerSyncInvoke(invocation);  if (response.isSuccessed()) {    // 在这里，response内的result会作为正常应答返回给业务逻辑    return consumerOperation.getResponseMapper().mapResponse(response);  }  // 这里是异常逻辑，response内的result即为错误信息，会被包装为InvocationException抛给业务逻辑  throw ExceptionFactory.convertConsumerException(response.getResult());}</code></pre><p>出现了线上日志中的错误说明这个方法没有走到throw语句，而是走return语句那里返回了。</p><p><code>InvokerUtils.innerSyncInvoke()</code>方法里触发的主要流程是Handler-&gt;HttpClientFilter-&gt;网络线程，既然在用户自定义的<code>HTTPClientFilter</code>实现类的<code>afterReceiveResponse()</code>方法中已经打印出了B服务返回的应答消息，那么网络线程部分的嫌疑就可以排除了。问题只可能出在<code>Invoker</code>、<code>Handler</code>、<code>HTTPClientFilter</code>这三块。这个异常需要被catch住并塞到<code>response</code>里。同时，为了让异常作为response body返回，而不是被“抛”出去，<code>response.isSuccessed()</code>需要返回<code>true</code>，这就要求<code>response</code>的Http状态码必须是2xx的。通过在demo中加入自定义的<code>HttpClientFilter</code>，在<code>afterReceiveResponse()</code>方法中抛出一个状态码为200的<code>InvocationException</code>，我们复现出了这个问题，其日志特征与A服务的线上日志一致。</p><h2 id="根因确定"><a href="#根因确定" class="headerlink" title="根因确定"></a>根因确定</h2><p>一个response，里面装着一个异常，Http状态码却是2xx的，这个场景应该是不会发生的才对。在向A服务的开发同学确认了他们没有在自定义的<code>Handler</code>、<code>HttpClientFilter</code>内直接操作response后，我们通过日志也无法给出问题结论，只能等A服务的开发同学本地复现问题场景了。</p><p>好在这个问题本地是能够复现出来的，根因是在于A服务依赖的B服务接口jar包被替换后，旧版本的业务接口应答类型比新版本的多一个属性，而且这个属性的类型是找不到的，大致像下面这样：</p><pre><code class="java">class ResponseType {  private InnerFieldType someField; // 这里的InnerFieldType会报ClassNotFound}</code></pre><p>于是当<code>DefaultHttpClientFilter</code>的<code>extractResult()</code>方法尝试将Http body中的json串反序列化为业务代码中的应答对象时，会抛出一个异常，而这个异常被包装成<code>InvocationException</code>后，是被“return”回去的，而不是“throw”出去的，并且这个过程中没有打印任何日志。关键代码在<code>DefaultHttpClientFilter</code>的85-89行：</p><pre><code class="java">try {  return produceProcessor.decodeResponse(responseEx.getBodyBuffer(), responseMeta.getJavaType());} catch (Exception e) {  return ExceptionFactory.createConsumerException(e); // 异常被返回}</code></pre><p>“return”回去的异常被作为正常的应答对象塞进了<code>response</code>中，而<code>response</code>的状态码是Http应答的状态码——200，于是就有了线上碰到的错误。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>ServiceComb框架在此次定位过程中暴露出来的缺少日志的问题会在后续版本中修复。但是对于开发者而言，更重要的是服务上线部署前需要做好充分验证，临时替换依赖jar包这种简单粗暴的处理方式不可取。</p><p>那么本地调试过程中碰到这种问题应该如何定位呢？以本文所描述的场景（RPC调用方式，同步运行模式）来看，当业务代码中触发一次微服务调用，ServiceComb的处理流程大致是：</p><blockquote><p>Invoker -&gt; InvokerUtils -&gt; Handler -&gt; HTTPClientFilter -&gt; 网络线程</p></blockquote><p><code>Invoker</code>是RPC调用模式下的动态代理，业务代码通过provider接口做调用时，参数首先被传到<code>invoke()</code>方法中。由于consumer工作于同步模式，<code>Invoker</code>会通过<code>syncInvoke()</code>方法调用<code>InvokerUtils</code>的<code>innerSyncInvoke()</code>方法。在这里，<code>Invocation</code>的<code>next()</code>方法被调用，<strong><em>从而触发Handler链执行</em></strong>。在Handler链的末尾是<code>TransportClientHandler</code>，它会调用对应的transport方式发送请求。在Rest over Vertx传输方式下，我们需要关注的是<code>RestClientInvocation</code>的<code>invoke()</code>方法，这里会<strong><em>遍历执行HttpClientFilter的beforeSendRequest()方法</em></strong>，然后将请求调度到网络线程中发送。业务线程此时处于等待返回的状态（<code>SyncResponseExecutor.waitResponse()</code>方法中使用<code>CountDownLatch</code>进行等待）。</p><p>当请求应答返回后，<code>RestClientInvocation.processResponseBody()</code>方法会将Http response body返回给业务线程处理（通过触发<code>SyncResponseExecutor</code>的<code>CountDownLatch</code>）。应答首先会在<code>RestClientInvocation</code>中<strong><em>遍历HttpClientFilter的afterReceiveResponse()方法</em></strong>进行处理，然后<strong><em>经过Handler链</em></strong>的回调处理，最终返回给<code>InvokerUtils</code>的<code>syncInvoke()</code>方法。其中，<strong><em>Http response body是在DefaultHttpClientFilter的extractResult()方法中反序列化为业务接口返回对象的</em></strong>。这个方法会根据<code>response</code>的HTTP状态码判断如何对待结果，如果是2xx的状态码，则<code>response</code>中的<code>result</code>会作为正常的应答返回给业务逻辑，否则会将<code>result</code>包装到<code>InvocationException</code>中抛给业务逻辑。</p><pre><code class="java">  // RestClientInvocation中处理应答的关键方法  protected void processResponseBody(Buffer responseBuf) {    invocation.getResponseExecutor().execute(() -&gt; {      // 同步模式下，应答返回流程从这里开始就是在业务线程里执行的      try {        HttpServletResponseEx responseEx =            new VertxClientResponseToHttpServletResponse(clientResponse, responseBuf);        for (HttpClientFilter filter : httpClientFilters) {          // HttpClientFilter处理返回消息体，普通的filter会返回null          Response response = filter.afterReceiveResponse(invocation, responseEx);          if (response != null) { // DefaultHttpClientFilter会把消息体反序列化为应答对象，装入response返回            asyncResp.complete(response); // 通过回调触发handler链            return;          }        }      } catch (Throwable e) {        asyncResp.fail(invocation.getInvocationType(), e); // 包装异常，通过回调触发handler链      }    });  }</code></pre><p>本地分析这类问题的时候，首先需要知道请求发送的流程，了解RPC动态代理的入口、<code>Handler</code>链的起止点、<code>HttpClientFilter</code>的调用点。这些是流程中的关键节点，根据这些信息可以大致确定问题出现的范围。至于更进一步的定位，就需要大家根据具体的问题进行分析了。</p><blockquote><p>看不懂上面说的是什么？正常 :P</p><p>只看一篇博客是很难弄懂这段流程的。关键的代码节点已经给出来了，自己写个demo调试一下，你的了解会更深刻</p><p>(￣▽￣)ﾉ</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
      <category>踩坑</category>
      
    </categories>
    
    
    <tags>
      
      <tag>microservice</tag>
      
      <tag>ServiceComb-Java-Chassis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【华为云微服务引擎】从代码机制看AK/SK认证问题</title>
    <link href="undefined2018/08/02/AKSKAuthenticationProblemLocation/"/>
    <url>2018/08/02/AKSKAuthenticationProblemLocation/</url>
    
    <content type="html"><![CDATA[<p>排查AK/SK认证问题的常见路径和底层代码分析。</p><a id="more"></a><h1 id="【华为云微服务引擎】从代码机制看AK-SK认证问题"><a href="#【华为云微服务引擎】从代码机制看AK-SK认证问题" class="headerlink" title="【华为云微服务引擎】从代码机制看AK/SK认证问题"></a>【华为云微服务引擎】从代码机制看AK/SK认证问题</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>用户开发的微服务要想注册到CSE的服务中心，就需要用到AK/SK认证。由于CSEJavaSDK提供了较多的配置方式，有时候容易出现错配和漏配的情况，本文从CSEJavaSDK读取AK/SK的关键代码入手进行分析，希望能够给大家提供一点AK/SK认证失败时的定位思路。（本文基于CSEJavaSDK-2.3.30进行说明）</p><h2 id="代码逻辑分析"><a href="#代码逻辑分析" class="headerlink" title="代码逻辑分析"></a>代码逻辑分析</h2><p>首先需要说明的是，AK/SK也是一个配置项，因此它可以配置在microservice.yaml文件里，可以通过-D设置系统属性来指定，也可以通过环境变量来指定（Windows的环境变量貌似可以带点号<code>.</code>，因此你可以直接在环境变量中指定cse.credentials.accessKey=ak；而Linux的环境变量不能带点，所以不能这么做）。另一方面来说，AK/SK又是一个比较特殊的配置项，因此CSEJavaSDK又提供了一个<a href="https://support.huaweicloud.com/devg-cse/cse_03_0088.html" target="_blank" rel="noopener">加密存储</a>的配置方式。无论AK/SK的来源是哪里，最终CSEJavaSDK都是在AKSKManager中完成AK/SK的读取逻辑的。</p><pre><code class="java">public static Credentials getCredential() throws Exception {  // 读取AK/SK  AKSKOption option = AKSKOption.readAKSK();  // 中间读写缓存等等逻辑忽略……  // 根据cse.credentials.akskCustomCipher配置获取cipher，对AK/SK进行解密    AKSKCipher cipher = (AKSKCipher)CIPHERS.get(option.getAkskCustomCipher());  // 检查逻辑忽略...    char[] ak = cipher.decode(TYPE.AK, option.getAccessKey().toCharArray());    char[] sk = cipher.decode(TYPE.SK, option.getSecretKey().toCharArray());    String project = option.getProject();    if (project == null || project.isEmpty()) {      // 如果用户没有配置cse.credentials.project，就尝试从配置的服务中心地址进行解析，具体的代码忽略……      // 我们平常通过APIGateway连接到服务中心，例如你要连到华北区，配置的地址就是这样的 https://cse.cn-north-1.myhuaweicloud.com      // 可以从中截取出 cn-north-1，这个就是华北区的project      LOGGER.info(&quot;The application missing project infomation, so choose a nearest one [{}]&quot;, project);    }  return credentials;}</code></pre><p>以上是AKSKManager的getCredential方法逻辑，可以看到大体的流程是读取AK/SK、根据cse.credentials.akskCustomCipher配置项获取cipher对aksk进行解密、获取cse.credentials.project配置信息。此方法返回的credentials内包含了明文的AK/SK、project信息，因此<strong><em>本地调试时确定AK/SK读取是否有问题的最快途径就是在getCredential方法末尾打断点，查看credentials包含的信息</em></strong>。</p><p>而在AKSKOption.readAKSK()中读取AK/SK的关键流程如下：</p><pre><code class="java">public static AKSKOption readAKSK() {  // 从AK/SK加密存储文件读取  AKSKOption option = readFromFile();  if (option == null) {    // 从配置中读取，注意：环境变量、System Property、配置文件都算在这里面    option = buildFromYaml();  }  return option;}private static AKSKOption readFromFile() {  // 忽略缓存逻辑……  // 先尝试从环境变量CIPHER_ROOT中读取加密存储文件的目录    String cipherPath = System.getenv(&quot;CIPHER_ROOT&quot;);    if (cipherPath == null || cipherPath.isEmpty()) {      // 若不存在则从/opt/CSE/etc/cipher目录中读取      cipherPath = &quot;/opt/CSE/etc/cipher&quot;;    }    String certFilePath = cipherPath + File.separator + &quot;certificate.yaml&quot;;    File certFile = new File(certFilePath);    if (!certFile.exists() || certFile.isDirectory()) {      // 文件不存在时尝试从系统属性user.dir配置的目录中读取      certFile = new File(System.getProperty(&quot;user.dir&quot;) + File.separator + &quot;certificate.yaml&quot;);      if (!certFile.exists() || certFile.isDirectory()) {        return null;      }    }    AKSKOption option = readFromFile(certFile);    return option;}</code></pre><p>可以看到CSEJavaSDK优先读取加密存储的AK/SK文件，读不到才去配置中找。而AK/SK加密文件的读取路径优先级从高到低分别是CIPHER_ROOT环境变量配置的目录、/opt/CSE/etc/cipher目录、user.dir系统属性配置的目录（这个少见）。</p><h2 id="常见问题分析思路"><a href="#常见问题分析思路" class="headerlink" title="常见问题分析思路"></a>常见问题分析思路</h2><p>当发生AK/SK认证失败的问题时，我们首先需要对问题有个基本的定界，即问题是出在AK/SK读取（解密）上，还是出在AK/SK的内容本身。</p><p>如果是本地开发调试，那么这个问题很好确定，直接在<code>AKSKManager</code>的<code>getCredential</code>方法里打断点去看一下即可。如果是在线上部署运行的服务，那么只能看日志，凭经验来定位了。与AK/SK认证相关的日志关键词有这些：</p><ul><li>“read ak/sk from”：显示AK/SK的来源是哪里，”read ak/sk from security storage file.”表示服务实例从AK/SK加密存储文件中读取配置项的，”read ak/sk from microservice.yaml.”表示服务实例从配置项中读物AK/SK的（注意，这里说的是<strong><em>配置项，包含了环境变量、系统属性以及配置文件</em></strong>，不单单是指microservice.yaml文件）。</li><li>“add ak/sk cipher”：加载<code>AKSKCipher</code>，cipher用于解密SK。CSEJavaSDK默认提供的cipher有default、security，default用于明文存储AK/SK的场景，security在<a href="https://support.huaweicloud.com/devg-cse/cse_03_0088.html" target="_blank" rel="noopener">AK/SK加密存储</a>场景中使用。CSEJavaSDK使用SPI机制加载cipher，如果发现日志中没有打印加载default和security的内容，那么你就需要检查一下自己依赖的jar包了。</li><li>“sign request failed …… OSS_ROOT not properly set”：当cipher为<code>security</code>时，CSEJavaSDK会去CIPHER_ROOT环境变量配置的目录里读取解密密钥文件common_shared.key和root.key，如果用户忘记配置CIPHER_ROOT了，就会打印这个错误。</li><li>“Cipher decode error, will use original as plain!”：SK解密失败时会打印此错误日志，常见的错误原因包括CIPHER_ROOT环境变量下没有密钥文件、程序没有权限读取密钥文件、Java没有开启高强度加密功能等。关于Java高强度加密功能，大家去网上搜一下JCE policy能找到解除限制的方法，较低版本的jdk8需要下载一个jce的jar包，高版本的直接修改jre目录下的lib/security/java.security文件配置即可，这个限制只存在于Oracle JDK中，OpenJDK没有此限制。</li><li>AK/SK或project配置内容错误：当内容配置出错时，实际上AK/SK的读取加密过程并不会报错，只有等到CSEJavaSDK向CSE后端服务（sc/cc/monitor）发送请求时，才会拿到错误返回消息，错误信息包括如下类型：<pre><code>AK内容错误：401:Unauthorized, {&quot;errorCode&quot;:&quot;401002&quot;,&quot;errorMessage&quot;:&quot;Request unauthorized&quot;,&quot;detail&quot;:&quot;Get service token from iam proxy failed,{\&quot;error\&quot;:\&quot;get SK from AK from iam failed. error:Object Not Found - details: \&quot;}&quot;}</code></pre><pre><code>SK内容错误：401:Unauthorized, {&quot;errorCode&quot;:&quot;401002&quot;,&quot;errorMessage&quot;:&quot;Request unauthorized&quot;,&quot;detail&quot;:&quot;Get service token from iam proxy failed,{\&quot;error\&quot;:\&quot;validate ak sk error\&quot;}&quot;}</code></pre><pre><code>project配置错误：401:Unauthorized, {&quot;errorCode&quot;:&quot;401002&quot;,&quot;errorMessage&quot;:&quot;Request unauthorized&quot;,&quot;detail&quot;:&quot;Get service token from iam proxy failed,{\&quot;error\&quot;:\&quot;get project token from iam failed. error:http post failed, statuscode: 400\&quot;}&quot;}</code></pre>这些错误内容都是华为云服务的认证鉴权机制返回的，后期如果相关服务升级的话，也许返回的错误内容会有变化。但总之大家可以抓住关键的一点，就是如果前面的AK/SK加载过程都没有报错，只有连接CSE后端服务时拿到401的错误返回，那么你就需要检查一下自己的AK/SK、project是否配置对了。-D启动参数、环境变量、各个microservice.yaml文件都是需要排查的。至于project的配置，可以参考<a href="https://support.huaweicloud.com/usermanual-iam/zh-cn_topic_0079477316.html" target="_blank" rel="noopener">如何查看项目ID</a>。project和你所连接的region是相关的，比如华北区连接的APIGateway地址就是<a href="https://cse.cn-north-1.myhuaweicloud.com" target="_blank" rel="noopener">https://cse.cn-north-1.myhuaweicloud.com</a> ，project应该配置为cn-north-1。如果你不配置，CSEJavaSDK会尝试从sc地址中截取出来，但不一定能拿到正确的值，此时启动日志里面会打印提示信息，例如”The application missing project infomation, so choose a nearest one [cn-north-1]”，就是在告诉你自动选取的project是cn-north-1。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>博主对AK/SK认证的了解大致也就是上面这些了，很多内容也只能提供一点参考和启发意义。项目实际运行的情况复杂多样，当大家遇到相关问题的时候还是需要根据上面提到的代码逻辑，结合自己服务的实际运行环境去分析，才能更好地定位问题。</p>]]></content>
    
    
    <categories>
      
      <category>软件技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ServiceComb</tag>
      
      <tag>CSE</tag>
      
      <tag>华为云</tag>
      
      <tag>microservice</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>